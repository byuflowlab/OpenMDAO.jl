var documenterSearchIndex = {"docs":
[{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"nonlinear_circuit/#A-More-Complicated-Example:-Nonlinear-Circuit","page":"A More Complicated Example","title":"A More Complicated Example: Nonlinear Circuit","text":"","category":"section"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"This tutorial will implement the nonlinear circuit example from the OpenMDAO docs in Julia. Along the way, we'll learn","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"how to create implicit components with OpenMDAO.jl\nhow to create OpenMDAO.jl components with metadata (the equivalent of options in a normal Python component)\nhow to specify default values for component metadata","category":"page"},{"location":"nonlinear_circuit/#Preamble","page":"A More Complicated Example","title":"Preamble","text":"","category":"section"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"We'll need the OpenMDAOCore package, of course:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"using OpenMDAOCore: OpenMDAOCore","category":"page"},{"location":"nonlinear_circuit/#An-Explicit-Component-with-an-Option:-The-Resistor","page":"A More Complicated Example","title":"An Explicit Component with an Option: The Resistor","text":"","category":"section"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Next we'll create an explicit component that models a resistor. The resistor has one option: the resistance, R. We'll make R a field in the Julia struct that we'll use for the Resistor component:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"struct Resistor <: OpenMDAOCore.AbstractExplicitComp\n    R::Float64\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Now we'd like to use a default value of 1.0 for the resistance. We can do that by creating an outer constructor for the Resistor struct with a default keyword value.","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"# Default value for R.\nResistor(; R=1.0) = Resistor(R)","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Next, we'll create a setup function as usual:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"function OpenMDAOCore.setup(self::Resistor)\n    input_data = [OpenMDAOCore.VarData(\"V_in\"; units=\"V\"), OpenMDAOCore.VarData(\"V_out\"; units=\"V\")]\n    output_data = [OpenMDAOCore.VarData(\"I\"; units=\"A\")]\n\n    R = self.R\n    partials_data = [OpenMDAOCore.PartialsData(\"I\", \"V_in\", val=1/R),\n                     OpenMDAOCore.PartialsData(\"I\", \"V_out\", val=-1/R),]\n\n    return input_data, output_data, partials_data\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Since this is a linear resistor, the derivatives are constant, and we can set them via the val argument in the PartialsData struct, just like in OpenMDAO's declare_partials method. Also notice that we can specify units for each of the inputs and outputs, just like in a Python OpenMDAO component.","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Finally, we'll implement the compute! method:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"function OpenMDAOCore.compute!(self::Resistor, inputs, outputs)\n    deltaV = inputs[\"V_in\"][1] - inputs[\"V_out\"][1]\n    outputs[\"I\"][1] = deltaV/self.R\n\n    return nothing\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Notice that we have access to the R field in the Resistor struct, named self here. (We could call it anything, just like in a Python method.)","category":"page"},{"location":"nonlinear_circuit/#An-Explicit-Component-with-Two-Options:-The-Diode","page":"A More Complicated Example","title":"An Explicit Component with Two Options: The Diode","text":"","category":"section"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"We need two parameters to characterize the Diode: the saturation current Is and the thermal voltage Vt:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"struct Diode <: OpenMDAOCore.AbstractExplicitComp\n    Is::Float64\n    Vt::Float64\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Next, we'll create an constructor that sets both options using keyword arguments, and provides default values for both.","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"# Use Julia's keyword arguments to set default values.\nDiode(; Is=1e-15, Vt=0.025875) = Diode(Is, Vt)","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Next, we'll implement the setup method for the Diode.","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"function OpenMDAOCore.setup(self::Diode)\n    input_data = [OpenMDAOCore.VarData(\"V_in\"; units=\"V\"), OpenMDAOCore.VarData(\"V_out\"; units=\"V\")]\n    output_data = [OpenMDAOCore.VarData(\"I\"; units=\"A\")]\n\n    partials_data = [OpenMDAOCore.PartialsData(\"I\", \"V_in\"), OpenMDAOCore.PartialsData(\"I\", \"V_out\")]\n\n    return input_data, output_data, partials_data\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Nothing unusual here.","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Finally, the compute! and compute_partials! methods:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"function OpenMDAOCore.compute!(self::Diode, inputs, outputs)\n    deltaV = inputs[\"V_in\"][1] - inputs[\"V_out\"][1]\n\tIs = self.Is\n\tVt = self.Vt\n    outputs[\"I\"][1] = Is * (exp(deltaV / Vt) - 1)\n    return nothing\nend\n\nfunction OpenMDAOCore.compute_partials!(self::Diode, inputs, J)\n\tdeltaV = inputs[\"V_in\"][1] - inputs[\"V_out\"][1]\n\tIs = self.Is\n\tVt = self.Vt\n\tI = Is * exp(deltaV / Vt)\n\n\tJ[\"I\", \"V_in\"][1, 1] = I/Vt\n\tJ[\"I\", \"V_out\"][1, 1] = -I/Vt\n\n\treturn nothing\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Like the Resistor, we have access to the Is and Vt options in the Diode struct in both methods.","category":"page"},{"location":"nonlinear_circuit/#Our-First-Implicit-Component:-The-Node","page":"A More Complicated Example","title":"Our First Implicit Component: The Node","text":"","category":"section"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Our final component we need for the circuit is an implicit one: the Node. Each node can have an arbitrary number of incoming and outgoing currents, so we'll need two integer options to keep track of that:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"struct Node <: OpenMDAOCore.AbstractImplicitComp\n    n_in::Int\n\tn_out::Int\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"We'll have n_in and n_out both default to one, though:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Node(; n_in=1, n_out=1) = Node(n_in, n_out)","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Next up is the setup method. We'll need to use a loop to create all the inputs and outputs needed for the component:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"function OpenMDAOCore.setup(self::Node)\n    output_data = [OpenMDAOCore.VarData(\"V\", val=5.0, units=\"V\")]\n\n    input_data = Vector{OpenMDAOCore.VarData}()\n    partials_data = Vector{OpenMDAOCore.PartialsData}()\n\n\tfor i in 0:self.n_in-1\n        i_name = \"I_in:$i\"\n        push!(input_data, OpenMDAOCore.VarData(i_name; units=\"A\"))\n        push!(partials_data, OpenMDAOCore.PartialsData(\"V\", i_name; val=1.0))\n\tend\n\n\tfor i in 0:self.n_out-1\n        i_name = \"I_out:$i\"\n        push!(input_data, OpenMDAOCore.VarData(i_name; units=\"A\"))\n        push!(partials_data, OpenMDAOCore.PartialsData(\"V\", i_name; val=-1.0))\n\tend\n\n\treturn input_data, output_data, partials_data\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"We could have done something fancier like an array comprehension to create the VarData and PartialsData structs:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"input_data = [OpenMDAOCore.VarData(\"I_in:$i\"; units=\"A\") for i in 0:self.n_in-1]","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Also, the derivatives are constant for the node, so we set them in the PartialsData struct.","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Finally, we just need to write the apply_nonlinear! method:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"function OpenMDAOCore.apply_nonlinear!(self::Node, inputs, outputs, residuals)\n    residuals[\"V\"][1] = 0.0\n    for i_conn in 0:self.n_in-1\n        residuals[\"V\"][1] += inputs[\"I_in:$i_conn\"][1]\n    end\n    for i_conn in 0:self.n_out-1\n        residuals[\"V\"][1] -= inputs[\"I_out:$i_conn\"][1]\n    end\n\n    return nothing\nend","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"We see that the apply_nonlinear! OpenMDAO.jl method is very similar to the apply_nonlinear method on a normal Python ImplicitComponent— its job is to calculate the residual of the implicit equation(s) it is modeling from the inputs and outputs.","category":"page"},{"location":"nonlinear_circuit/#The-Run-Script","page":"A More Complicated Example","title":"The Run Script","text":"","category":"section"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"We're finally ready for the run script! Here it is:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"using OpenMDAO: om, make_component\n\np = om.Problem()\n\ncircuit = om.Group()\n\ncircuit.add_subsystem(\"n1\", make_component(Node(n_in=1, n_out=2)), promotes_inputs=[(\"I_in:0\", \"I_in\")])\ncircuit.add_subsystem(\"n2\", make_component(Node()))\n\ncircuit.add_subsystem(\"R1\", make_component(Resistor(R=100.0)), promotes_inputs=[(\"V_out\", \"Vg\")])\ncircuit.add_subsystem(\"R2\", make_component(Resistor(R=10000.0)))\ncircuit.add_subsystem(\"D1\", make_component(Diode()), promotes_inputs=[(\"V_out\", \"Vg\")])\n\ncircuit.connect(\"n1.V\", [\"R1.V_in\", \"R2.V_in\"])\ncircuit.connect(\"R1.I\", \"n1.I_out:0\")\ncircuit.connect(\"R2.I\", \"n1.I_out:1\")\n\ncircuit.connect(\"n2.V\", [\"R2.V_out\", \"D1.V_in\"])\ncircuit.connect(\"R2.I\", \"n2.I_in:0\")\ncircuit.connect(\"D1.I\", \"n2.I_out:0\")\n\ncircuit.nonlinear_solver = om.NewtonSolver()\ncircuit.linear_solver = om.DirectSolver()\n\ncircuit.nonlinear_solver.options[\"iprint\"] = 2\ncircuit.nonlinear_solver.options[\"maxiter\"] = 10\ncircuit.nonlinear_solver.options[\"solve_subsystems\"] = true\ncircuit.nonlinear_solver.linesearch = om.ArmijoGoldsteinLS()\ncircuit.nonlinear_solver.linesearch.options[\"maxiter\"] = 10\ncircuit.nonlinear_solver.linesearch.options[\"iprint\"] = 2\n\np.model.add_subsystem(\"circuit\", circuit)\n\np.setup()\n\np.set_val(\"circuit.I_in\", 0.1)\np.set_val(\"circuit.Vg\", 0.)\n\n# set some initial guesses\np.set_val(\"circuit.n1.V\", 10.)\np.set_val(\"circuit.n2.V\", 1e-3)\n\np.run_model()\n\nprintln(\"circuit.n1.V = $(p[\"circuit.n1.V\"]) (should be 9.90804735)\")\nprintln(\"circuit.n2.V = $(p[\"circuit.n2.V\"]) (should be 0.71278185)\")\nprintln(\"circuit.R1.I = $(p[\"circuit.R1.I\"]) (should be 0.09908047)\")\nprintln(\"circuit.R2.I = $(p[\"circuit.R2.I\"]) (should be 0.00091953)\")\nprintln(\"circuit.D1.I = $(p[\"circuit.D1.I\"]) (should be 0.00091953)\")\n\n# sanity check: should sum to .1 Amps\nprintln(\"circuit.R1.I + circuit.D1.I = $(p[\"circuit.R1.I\"] + p[\"circuit.D1.I\"]) (should be 0.1)\")","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"Notice that:","category":"page"},{"location":"nonlinear_circuit/","page":"A More Complicated Example","title":"A More Complicated Example","text":"We can use Groups and connect methods just like a Python OpenMDAO program\nLinear and nonlinear solvers, and linesearch objects also work fine\nWe get the same answers as the Python example in the OpenMDAO docs! :-)","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"dev_docs/#Developer-Docs","page":"Developer Docs","title":"Developer Docs","text":"","category":"section"},{"location":"dev_docs/#Getting-Full-Stacktraces-from-Documentation-Example-Blocks","page":"Developer Docs","title":"Getting Full Stacktraces from Documentation Example Blocks","text":"","category":"section"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"# https://github.com/JuliaDocs/Documenter.jl/issues/1420\ntry\n    # Do the thing that's throwing the error\ncatch err\n    showerror(stderr, err, catch_backtrace())\nend","category":"page"},{"location":"dev_docs/#How-to-Release-a-New-Version","page":"Developer Docs","title":"How to Release a New Version","text":"","category":"section"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"For either OpenMDAOCore.jl or OpenMDAO.jl, registering a new version should be as simple as commenting","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"@JuliaRegistrator register subdir=julia/OpenMDAOCore.jl","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"or","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"@JuliaRegistrator register subdir=julia/OpenMDAO.jl","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"on a new issue, like here. Be sure to adjust the version field in the appropriate Project.toml before you do that. And after the new version is registered, don't forget to tag it as suggested by the JuliaRegistrator bot. For example, OpenMDAOCore.jl version 0.3.1 was tagged like this:","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"$ git tag OpenMDAOCore.jl-v0.3.1 ea03a4e1be02a989021e5b466fc1fe51534e6fdb\n$ git push upstream OpenMDAOCore.jl-v0.3.1","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"where upstream is the remote corresponding to byuflowlab/OpenMDAO.jl.git:","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"$ git remote -v\norigin  git@github.com:dingraha/OpenMDAO.jl.git (fetch)\norigin  git@github.com:dingraha/OpenMDAO.jl.git (push)\nupstream        git@github.com:byuflowlab/OpenMDAO.jl.git (fetch)\nupstream        git@github.com:byuflowlab/OpenMDAO.jl.git (push)\n$","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"For omjlcomps, registration is done by manually running the \"Register to PyPI\" workflow from the GitHub Actions tab (basically copied from PythonCall.jl). Be sure to adjust the version in the python/setup.py file before registering a new version. After clicking on the Actions tab on https://github.com/byuflowlab/OpenMDAO.jl, you'll see \"Register to PyPI\" listed under \"All workflows\" on the left-hand side. Click on that, then click on the \"Run workflow\" dropdown button on the right-hand side of the screen. Run it from the master branch, then wait for the workflow to finish. After that, you should see the new version of omjlcomps on PyPI: https://pypi.org/project/omjlcomps/. Once that's done, tag the commit that contains the new version of omjlcomps and push that to byuflowlab/OpenMDAO.jl.git. For example, omjlcomps version 0.2.3 was tagged with","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"$ git tag omjlcomps-v0.2.3 d7830552dc3d54fe18b89dc91b36219739d13a62\n$ git push upstream omjlcomps-v0.2.3","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"where upstream is the remote corresponding to byuflowlab/OpenMDAO.jl.git:","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"$ git remote -v\norigin  git@github.com:dingraha/OpenMDAO.jl.git (fetch)\norigin  git@github.com:dingraha/OpenMDAO.jl.git (push)\nupstream        git@github.com:byuflowlab/OpenMDAO.jl.git (fetch)\nupstream        git@github.com:byuflowlab/OpenMDAO.jl.git (push)\n$","category":"page"},{"location":"dev_docs/#How-to-Release-a-New-Version-(Old,-LocalRegistry-Way)","page":"Developer Docs","title":"How to Release a New Version (Old, LocalRegistry Way)","text":"","category":"section"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"Note This section of the docs describes how I released new versions of OpenMDAO{,Core}.jl and omjlcomps before getting stuff registered in the Julia General registry. They are outdated and unnecessary, but I'm keeping them for now in case someone wants to do something similar down the road.","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"It's a bit tricky to release a new version of OpenMDAO.jl, since this repository contains 3 separate software packages: the Julia packages OpenMDAOCore.jl and OpenMDAO.jl, and the Python package omjlcomps. Here's how to do it.","category":"page"},{"location":"dev_docs/#Step-1:-Hack-on-OpenMDAO.jl","page":"Developer Docs","title":"Step 1: Hack on OpenMDAO.jl","text":"","category":"section"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"The first step of releasing a new version is obviously hacking on the code, which is no different than working on any other piece of software on GitHub. You'll need to fork the byuflowlab/OpenMDAO.jl GitHub repository, then clone it to your local machine with","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"$ git clone git@github.com:<your_user_name>/OpenMDAO.jl.git","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"Then you can start making changes, hopefully in a new local feature branch you create.","category":"page"},{"location":"dev_docs/#Step-2:-Submit-a-PR-to-byuflowlab/OpenMDAO.jl.git-and-merge","page":"Developer Docs","title":"Step 2: Submit a PR to byuflowlab/OpenMDAO.jl.git and merge","text":"","category":"section"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"After you're happy with your changes (they have tests, right? And pass those tests?), push your local changes to your GitHub fork, and then submit a PR to byuflowlab/OpenMDAO.jl.git. Be sure to bump the version number in each sub-package appropriately (if necessary: no need to modify all three version numbers just because a change was made to only one or two of the packages). The OpenMDAOCore.jl and OpenMDAO.jl version numbers should follow semantic versioning (check out the Julia Pkg docs on compatibility). I try to follow semantic versioning with the omjlcomps Python package, even though semantic versioning doesn't appear to be as pervasive in the Python ecosystem as it is in Julia land.","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"After everyone is satisfied with the PR, an Administrator of the byuflowab/OpenMDAO.jl repository will merge the package.","category":"page"},{"location":"dev_docs/#Step-3:-Tag-the-new-version(s)","page":"Developer Docs","title":"Step 3: Tag the new version(s)","text":"","category":"section"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"Every time the version of any of the three OpenMDAO.jl sub-packages is bumped, we should tag a new version. The way to do this is the following:","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"First, check out the upstream master branch, i.e. if the remote branch pointing to byuflowlab/OpenMDAO.jl.git is upstream, then do git checkout upstream/master. That should put the local repository in a \"detached HEAD\" state, like this:\n$ git checkout upstream/master\nNote: switching to 'upstream/master'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at a9e8f78 Merge pull request #16 from dingraha/licence\n$\nMake sure you're on the commit corresponding to the merged pull request you want to release/tag, using, for example, git log -n1:\n$ git log -n 1\ncommit a9e8f7849844640f77a2eadd3683476be92ba8fb (HEAD, upstream/master, origin/master, origin/HEAD, master, how_to_release)\nMerge: 16f0355 054b78c\nAuthor: Daniel Ingraham <d.j.ingraham@gmail.com>\nDate:   Thu May 25 09:02:07 2023 -0400\n\n    Merge pull request #16 from dingraha/licence\n    \n    Add LICENSE\n$ \nCreate the tag(s) using git tag. The tag or tags should follow the format package_name-vX.Y.Z. For example, here are the tags at the time of writing:\n$ git tag\nOpenMDAO.jl-v0.3.0\nOpenMDAO.jl-v0.3.1\nOpenMDAO.jl-v0.3.2\nOpenMDAO.jl-v0.4.0\nOpenMDAOCore.jl-v0.2.10\nOpenMDAOCore.jl-v0.2.8\nOpenMDAOCore.jl-v0.2.9\nOpenMDAOCore.jl-v0.3.0\nomjlcomps-v0.1.7\nomjlcomps-v0.1.8\nomjlcomps-v0.1.9\nomjlcomps-v0.2.0\nv0.2.0\nv0.2.1\n$ \n(The v0.2.0 and v0.2.1 tags are from very early versions of OpenMDAO.jl and don't follow the recomended tag format.)\nWith the tags created, all that's left is to push them to upstream:\n$ git push --tags upstream","category":"page"},{"location":"dev_docs/#Step-4:-Release-the-new-version(s)-to-the-appropriate-registries","page":"Developer Docs","title":"Step 4: Release the new version(s) to the appropriate registries","text":"","category":"section"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"For either of the two Julia packages (OpenMDAO.jl and OpenMDAOCore.jl), we need to register a new version with DanielIngrahamRegistry at dingraha/DanielIngrahamRegistry on GitHub using LocalRegistry. Again, this is unfortunately something only I (Daniel) can do. All that needs to be done is, from the Julia REPL:","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"Make sure you've deved the package you want to release, and are on the appropriate commit.\nDo LocalRegistry.register(\"OpenMDAOCore\") and/or LocalRegistry.register(\"OpenMDAO\"), as appropriate.","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"If a new version of omjlcomps was tagged, then we need to put it on PyPI. The way I do this currently is using twine:","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"$ # In the OpenMDAO.jl/python directory.\n$ python setup.py sdist\nrunning sdist\nrunning egg_info\nwriting omjlcomps.egg-info/PKG-INFO\nwriting dependency_links to omjlcomps.egg-info/dependency_links.txt\nwriting entry points to omjlcomps.egg-info/entry_points.txt\nwriting requirements to omjlcomps.egg-info/requires.txt\nwriting top-level names to omjlcomps.egg-info/top_level.txt\nreading manifest file 'omjlcomps.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwriting manifest file 'omjlcomps.egg-info/SOURCES.txt'\nrunning check\ncreating omjlcomps-0.1.9\ncreating omjlcomps-0.1.9/omjlcomps\ncreating omjlcomps-0.1.9/omjlcomps.egg-info\ncreating omjlcomps-0.1.9/omjlcomps/test\ncopying files to omjlcomps-0.1.9...\ncopying MANIFEST.in -> omjlcomps-0.1.9\ncopying README.md -> omjlcomps-0.1.9\ncopying setup.py -> omjlcomps-0.1.9\ncopying omjlcomps/__init__.py -> omjlcomps-0.1.9/omjlcomps\ncopying omjlcomps/juliapkg.json -> omjlcomps-0.1.9/omjlcomps\ncopying omjlcomps.egg-info/PKG-INFO -> omjlcomps-0.1.9/omjlcomps.egg-info\ncopying omjlcomps.egg-info/SOURCES.txt -> omjlcomps-0.1.9/omjlcomps.egg-info\ncopying omjlcomps.egg-info/dependency_links.txt -> omjlcomps-0.1.9/omjlcomps.egg-info\ncopying omjlcomps.egg-info/entry_points.txt -> omjlcomps-0.1.9/omjlcomps.egg-info\ncopying omjlcomps.egg-info/requires.txt -> omjlcomps-0.1.9/omjlcomps.egg-info\ncopying omjlcomps.egg-info/top_level.txt -> omjlcomps-0.1.9/omjlcomps.egg-info\ncopying omjlcomps/test/__init__.py -> omjlcomps-0.1.9/omjlcomps/test\ncopying omjlcomps/test/test_ecomp.jl -> omjlcomps-0.1.9/omjlcomps/test\ncopying omjlcomps/test/test_icomp.jl -> omjlcomps-0.1.9/omjlcomps/test\ncopying omjlcomps/test/test_julia_explicit_comp.py -> omjlcomps-0.1.9/omjlcomps/test\ncopying omjlcomps/test/test_julia_implicit_comp.py -> omjlcomps-0.1.9/omjlcomps/test\nWriting omjlcomps-0.1.9/setup.cfg\nCreating tar archive\nremoving 'omjlcomps-0.1.9' (and everything under it)\n(venv) dingraha@GRLRL2021060743 ~/p/p/d/O/python (master %)> ls\nbuild/  dist/  MANIFEST.in  omjlcomps/  omjlcomps.egg-info/  README.md  setup.py\n(venv) dingraha@GRLRL2021060743 ~/p/p/d/O/python (master %)> twine upload dist/omjlcomps-0.1.9.tar.gz \nUploading distributions to https://upload.pypi.org/legacy/\nEnter your username: dingraha\nEnter your password: \nUploading omjlcomps-0.1.9.tar.gz\n100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.1/12.1 kB • 00:00 • 8.5 MB/s\n\nView at:\nhttps://pypi.org/project/omjlcomps/0.1.9/\n$ ","category":"page"},{"location":"dev_docs/","page":"Developer Docs","title":"Developer Docs","text":"That unfortunately is something only I can do, since it requires my username and password for PyPI. Also it uses plain password authentication, which I think isn't supported anymore, or won't be for long.","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"simple_paraboloid/#A-Simple-Example:-Optimizing-a-Paraboloid","page":"A Simple Example","title":"A Simple Example: Optimizing a Paraboloid","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"We're going to duplicate the Paraboloid example from the OpenMDAO documentation, but implement the single ExplicitComponent in Julia instead of Python. The goal of this tutorial is to minimize the paraboloid","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"f(xy) = (x - 30)^2 + xy + (y + 40)^2 - 30","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"with respect to x and y. The OpenMDAO docs say the answer is x = frac203 approx 6667 and y = -frac223 approx -7333. Let's find out!","category":"page"},{"location":"simple_paraboloid/#The-Python-Implementation","page":"A Simple Example","title":"The Python Implementation","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"One possible Python implementation of the above paraboloid is this:","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"import openmdao.api as om\n\n\nclass Paraboloid(om.ExplicitComponent):\n    \"\"\"\n    Evaluates the equation f(x,y) = (x-3)^2 + xy + (y+4)^2 - 3.\n    \"\"\"\n\n    def setup(self):\n        self.add_input('x', val=0.0)\n        self.add_input('y', val=0.0)\n\n        self.add_output('f_xy', val=0.0)\n\n        # Finite difference all partials.\n        self.declare_partials('*', '*', method='fd')\n\n    def compute(self, inputs, outputs):\n        \"\"\"\n        f(x,y) = (x-3)^2 + xy + (y+4)^2 - 3\n\n        Minimum at: x = 6.6667; y = -7.3333\n        \"\"\"\n        x = inputs['x']\n        y = inputs['y']\n\n        outputs['f_xy'] = (x - 3.0)**2 + x * y + (y + 4.0)**2 - 3.0","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"Not too bad. How do we do it in Julia?","category":"page"},{"location":"simple_paraboloid/#The-Julia-Implementation","page":"A Simple Example","title":"The Julia Implementation","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"Like this, using OpenMDAOCore.jl:","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"using OpenMDAOCore: OpenMDAOCore\n\nstruct Paraboloid <: OpenMDAOCore.AbstractExplicitComp\nend\n\nfunction OpenMDAOCore.setup(self::Paraboloid)\n    inputs = [OpenMDAOCore.VarData(\"x\", val=0.0), OpenMDAOCore.VarData(\"y\", val=0.0)]\n    outputs = [OpenMDAOCore.VarData(\"f_xy\", val=0.0)]\n    partials = [OpenMDAOCore.PartialsData(\"*\", \"*\", method=\"fd\")]\n    return inputs, outputs, partials\nend\n\nfunction OpenMDAOCore.compute!(self::Paraboloid, inputs, outputs)\n    x = inputs[\"x\"][1]\n    y = inputs[\"y\"][1]\n\n    outputs[\"f_xy\"][1] = (x - 3.0)^2 + x * y + (y + 4.0)^2 - 3.0\n\n    return nothing\nend","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"What does all that mean? We'll go through it step by step.","category":"page"},{"location":"simple_paraboloid/#Step-1:-Preamble","page":"A Simple Example","title":"Step 1: Preamble","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"using OpenMDAOCore: OpenMDAOCore","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"This line loads the OpenMDAOCore.jl Julia package. Julia uses two different keywords for loading code from Julia modules: using and import. The official Julia docs on Modules do a good job of explaining the difference. I like doing using Foo: Foo because it brings the module name Foo into the current scope, but not any of the names inside of Foo, so it doesn't clutter the namespace. (The statement using Foo: Foo is kind of like Julia's version of import foo in Python, while just plain using Foo is like Python's from foo import *.)","category":"page"},{"location":"simple_paraboloid/#Step-2:-The-Paraboloid-struct","page":"A Simple Example","title":"Step 2: The Paraboloid struct","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"struct Paraboloid <: OpenMDAOCore.AbstractExplicitComp\nend","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"This bit of code defines a new type in Julia named Paraboloid. The <: is the subtype operator in Julia, so we are telling Julia that our new Paraboloid type is a subtype of the AbstractExplicitComp type defined in OpenMDAOCore. This is the Julian equivalent of","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"class Paraboloid(om.ExplicitComponent):","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"in Python.","category":"page"},{"location":"simple_paraboloid/#Step-3:-OpenMDAOCore.setup","page":"A Simple Example","title":"Step 3: OpenMDAOCore.setup","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"function OpenMDAOCore.setup(self::Paraboloid)\n    inputs = [OpenMDAOCore.VarData(\"x\", val=0.0), OpenMDAOCore.VarData(\"y\", val=0.0)]\n    outputs = [OpenMDAOCore.VarData(\"f_xy\", val=0.0)]\n    partials = [OpenMDAOCore.PartialsData(\"*\", \"*\", method=\"fd\")]\n    return inputs, outputs, partials\nend","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"This OpenMDAOCore.setup method is the Julian equivalent of the ExplicitComponent.setup method from the Python version of the paraboloid. The job of OpenMDAOCore.setup is to take a single argument (an OpenMDAOCore.AbstractExplicitComp or OpenMDAOCore.AbstractImplicitComp) and return three things:","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"A Vector of VarData structs containing metadata for the inputs to the component\nA Vector of VarData structs containing metadata for the outputs of the component\nA Vector of PartialsData structs containing metadata for the partial derivatives of the component","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"These Julia Vectors must always be returned in that order: inputs, outputs, partials. OpenMDAO.jl uses the VarData entries in the inputs and outputs Vectors to construct arguments to the Component.add_input and Component.add_output, respectively. And OpenMDAO.jl uses the PartialsData entries in the partials Vector to construct arguments to Component.declare_partials. The OpenMDAOCore.VarData and OpenMDAOCore.PartialsData docstrings have all the details.","category":"page"},{"location":"simple_paraboloid/#Step-4:-OpenMDAOCore.compute!","page":"A Simple Example","title":"Step 4: OpenMDAOCore.compute!","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"function OpenMDAOCore.compute!(self::Paraboloid, inputs, outputs)\n    x = inputs[\"x\"][1]\n    y = inputs[\"y\"][1]\n\n    outputs[\"f_xy\"][1] = (x - 3.0)^2 + x * y + (y + 4.0)^2 - 3.0\n\n    return nothing\nend","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"This OpenMDAOCore.compute! method is the equivalent of the Paraboloid.compute method from the Python version of the Paraboloid. Its job is to take a Paraboloid struct and a Dict of inputs, calculate the outputs, and then store these outputs in the outputs Dict. The inputs and outputs Dict entries are Julia arrays, similar to the NumPy arrays that OpenMDAO uses. (They are actually PyArrays from the PythonCall package, which are wrappers around the NumPy arrays that OpenMDAO creates for us.)","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"Now we need to figure out how to get that Julia code into OpenMDAO. How we do that depends on whether we're following the Python-Centric Approach or Julia-Centric Approach.","category":"page"},{"location":"simple_paraboloid/#The-Python-Centric-Run-Script","page":"A Simple Example","title":"The Python-Centric Run Script","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"We'll use JuliaCall, provided by the PythonCall package, to import the Julia code from the previous section into Python. Then we can use the omjlcomps Python package to create an OpenMDAO ExplicitComponent from the Paraboloid Julia struct, and write a run script as usual.","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"import openmdao.api as om\n\n# Create a new Julia module that will hold all the Julia code imported into this Python module.\nimport juliacall; jl = juliacall.newmodule(\"ParaboloidExample\")\n\n# This assumes the file with the Julia Paraboloid implementation is in the current directory and is named `paraboloid.jl`.\njl.include(\"paraboloid.jl\")\n# Now we have access to everything in `paraboloid.jl`.\n\n# omjlcomps knows how to create an OpenMDAO ExplicitComponent from an OpenMDAOCore.AbstractExplicitComp\nfrom omjlcomps import JuliaExplicitComp\ncomp = JuliaExplicitComp(jlcomp=jl.Paraboloid())\n\n# Now everything else is the same as https://openmdao.org/newdocs/versions/latest/basic_user_guide/single_disciplinary_optimization/first_analysis.html\nmodel = om.Group()\nmodel.add_subsystem('parab_comp', comp)\n\nprob = om.Problem(model)\n\nprob.driver = om.ScipyOptimizeDriver()\nprob.driver.options['optimizer'] = 'SLSQP'\n\nprob.model.add_design_var('parab_comp.x')\nprob.model.add_design_var('parab_comp.y')\nprob.model.add_objective('parab_comp.f_xy')\n\nprob.setup()\n\nprob.set_val('parab_comp.x', 3.0)\nprob.set_val('parab_comp.y', -4.0)\n\nprob.run_model()\nprint(prob['parab_comp.f_xy'])  # Should print `[-15.]`\n\nprob.set_val('parab_comp.x', 5.0)\nprob.set_val('parab_comp.y', -2.0)\n\nprob.run_model()\nprint(prob.get_val('parab_comp.f_xy'))  # Should print `[-5.]`\n\nprob.run_driver()\nprint(f\"f_xy = {prob.get_val('parab_comp.f_xy')}\")  # Should print `[-27.33333333]`\nprint(f\"x = {prob.get_val('parab_comp.x')}\")  # Should print `[6.66666633]`\nprint(f\"y = {prob.get_val('parab_comp.y')}\")  # Should print `[-7.33333367]`","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"The above Python run script should look pretty familiar if you have experience using OpenMDAO. The only difference from a pure-Python version is the little bit at the top that we use to create the JuliaExplicitComp.","category":"page"},{"location":"simple_paraboloid/#The-Julia-Centric-Run-Script","page":"A Simple Example","title":"The Julia-Centric Run Script","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"Now let's see if we can write a Julia run script:","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"using OpenMDAO: om, make_component\n\nprob = om.Problem()\n\n# omjlcomps knows how to create an OpenMDAO ExplicitComponent from an OpenMDAOCore.AbstractExplicitComp\ncomp = make_component(Paraboloid())\n\nmodel = om.Group()\nmodel.add_subsystem(\"parab_comp\", comp)\n\nprob = om.Problem(model)\n\nprob.driver = om.ScipyOptimizeDriver()\nprob.driver.options[\"optimizer\"] = \"SLSQP\"\n\nprob.model.add_design_var(\"parab_comp.x\")\nprob.model.add_design_var(\"parab_comp.y\")\nprob.model.add_objective(\"parab_comp.f_xy\")\n\nprob.setup()\n\nprob.set_val(\"parab_comp.x\", 3.0)\nprob.set_val(\"parab_comp.y\", -4.0)\n\nprob.run_model()\nprintln(prob[\"parab_comp.f_xy\"])  # Should print `[-15.]`\n\nprob.set_val(\"parab_comp.x\", 5.0)\nprob.set_val(\"parab_comp.y\", -2.0)\n\nprob.run_model()\nprintln(prob.get_val(\"parab_comp.f_xy\"))  # Should print `[-5.]`\n\nprob.run_driver()\nprintln(\"f_xy = $(prob.get_val(\"parab_comp.f_xy\"))\")  # Should print `[-27.33333333]`\nprintln(\"x = $(prob.get_val(\"parab_comp.x\"))\")  # Should print `[6.66666633]`\nprintln(\"y = $(prob.get_val(\"parab_comp.y\"))\")  # Should print `[-7.33333367]`","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"(This example assumes that the definition of the Paraboloid struct is included in the same file. So concatenate those two code blocks if you'd like to run this yourself.) Good news—we got the expected answer!","category":"page"},{"location":"simple_paraboloid/#Adding-Derivatives","page":"A Simple Example","title":"Adding Derivatives","text":"","category":"section"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"In the previous example we used OpenMDAO's finite difference method to approximate the paraboloid's partial derivatives. We can calculate them ourselves, though, just like in a Python OpenMDAO Component. Here's the implementation:","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"using OpenMDAOCore: OpenMDAOCore\n\nstruct ParaboloidUserPartials <: OpenMDAOCore.AbstractExplicitComp\nend\n\nfunction OpenMDAOCore.setup(self::ParaboloidUserPartials)\n    inputs = [OpenMDAOCore.VarData(\"x\", val=0.0), OpenMDAOCore.VarData(\"y\", val=0.0)]\n    outputs = [OpenMDAOCore.VarData(\"f_xy\", val=0.0)]\n    partials = [OpenMDAOCore.PartialsData(\"*\", \"*\")]\n    return inputs, outputs, partials\nend\n\nfunction OpenMDAOCore.compute!(self::ParaboloidUserPartials, inputs, outputs)\n    x = inputs[\"x\"][1]\n    y = inputs[\"y\"][1]\n\n    outputs[\"f_xy\"][1] = (x - 3.0)^2 + x * y + (y + 4.0)^2 - 3.0\n\n    return nothing\nend\n\nfunction OpenMDAOCore.compute_partials!(self::ParaboloidUserPartials, inputs, partials)\n    x = inputs[\"x\"][1]\n    y = inputs[\"y\"][1]\n\n    partials[\"f_xy\", \"x\"][1] = 2*(x - 3.0) + y\n    partials[\"f_xy\", \"y\"][1] = x + 2*(y + 4.0)\n\n    return nothing\nend","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"The implementation of ParaboloidUserPartials is almost the same as Paraboloid. The are only two differences:","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"We've removed the method=\"fd\" argument from the call to the PartialsData constructor. This means the method argument will default to \"exact\" (as shown in the docstring above), and OpenMDAO will expect we'll calculate the derivatives of this component ourselves.\nWe've implemented a compute_partials! method for our new ParaboloidUserPartials struct. This is just like an ExplicitComponent.compute_partials method in a Python OpenMDAO component. Its job is to calculate the the derivatives of the outputs with respect to the inputs, of course.","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"So, we implemented a compute_partials! method. But how do we know if they're right? The OpenMDAO Problem class has a method called check_partials that compares the user-defined partial derivatives to the finite difference method. Can we use that with an OpenMDAOCore.AbstractExplicitComp? Let's try!","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"using OpenMDAO: om, make_component\n\nprob = om.Problem()\n\n# omjlcomps knows how to create an OpenMDAO ExplicitComponent from an OpenMDAOCore.AbstractExplicitComp\ncomp = make_component(ParaboloidUserPartials())\n\nmodel = om.Group()\nmodel.add_subsystem(\"parab_comp\", comp)\n\nprob = om.Problem(model)\n\nprob.driver = om.ScipyOptimizeDriver()\nprob.driver.options[\"optimizer\"] = \"SLSQP\"\n\nprob.model.add_design_var(\"parab_comp.x\")\nprob.model.add_design_var(\"parab_comp.y\")\nprob.model.add_objective(\"parab_comp.f_xy\")\n\nprob.setup(force_alloc_complex=true)\n\nprob.set_val(\"parab_comp.x\", 3.0)\nprob.set_val(\"parab_comp.y\", -4.0)\n\nprob.run_model()\nprintln(prob.check_partials(method=\"fd\"))","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"It worked! And the error is quite small.","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"What about the complex step method?","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"println(prob.check_partials(method=\"cs\"))","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"It works! (The error is zero since the complex-step method is second-order accurate and we're differentiating a second-order polynomial.) Complex numbers are no problem for Julia, but just like Python, we need to be careful to write our compute_partials! function in a complex-step-safe manner.","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"note: FLOWMath.jl\nThe Julia library FLOWMath has a collection of complex-step-safe functions.","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"Now, let's try an optimization:","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"prob.run_driver()\nprintln(\"f_xy = $(prob.get_val(\"parab_comp.f_xy\"))\")  # Should print `[-27.33333333]`\nprintln(\"x = $(prob.get_val(\"parab_comp.x\"))\")  # Should print `[6.66666633]`\nprintln(\"y = $(prob.get_val(\"parab_comp.y\"))\")  # Should print `[-7.33333367]`","category":"page"},{"location":"simple_paraboloid/","page":"A Simple Example","title":"A Simple Example","text":"Still works, and we got the right answer.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"shape_by_conn/#Variable-Shapes-at-Runtime:-shape_by_conn-and-copy_shape","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime: shape_by_conn and copy_shape","text":"","category":"section"},{"location":"shape_by_conn/#A-Simple-Example","page":"Variable Shapes at Runtime","title":"A Simple Example","text":"","category":"section"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"OpenMDAO is able to determine variable shapes at runtime. In \"normal\" (aka non-Julian) OpenMDAO, this is done via the shape_by_conn and copy_shape arguments to the venerable add_input and/or add_output Component methods. In OpenMDAO.jl, we can provide the shape_by_conn and/or copy_shape arguments to the VarData struct constructor to get the same behavior.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"We'll show how this works using a simple ExplicitComponent that computes y = 2*x^2 + 1 element-wise, where x and y are two-dimensional arrays of any (identical) size.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"We'll need OpenMDAOCore of course, and need to declare our ExplicitComponent in the usual way:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"using OpenMDAOCore: OpenMDAOCore\n\nstruct ECompShapeByConn <: OpenMDAOCore.AbstractExplicitComp end","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Next we need a setup method:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"function OpenMDAOCore.setup(self::ECompShapeByConn)\n    input_data = [OpenMDAOCore.VarData(\"x\"; shape_by_conn=true)]\n    output_data = [OpenMDAOCore.VarData(\"y\"; shape_by_conn=true, copy_shape=\"x\")]\n\n    partials_data = []\n    return input_data, output_data, partials_data\nend","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Notice how we provided the shape_by_conn argument to the VarData struct for x, and the shape_by_conn and copy_shape arguments to y's VarData struct. This means that the shape of x will be determined at runtime by OpenMDAO, and will be set to the shape of whatever output is connected to x. The shape of y will be set to that of x, since we provided the copy_shape=\"x\" argument. (Also notice how we returned an empty Vector for the partials_data output—OpenMDAO.jl always expects OpenMDAOCore.setup to return three Vectors, corresponding to input_data, output_data, and partials_data. But the partials_data Vector can be empty if it's not needed.)","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Now, the derivative of y with respect to x will be sparse—the value of an element y[i,j] depends on the element x[i,j], and no others. We can communicate this fact to OpenMDAO through the rows and cols arguments to declare_partials in Python OpenMDAO, or the PartialsData struct in OpenMDAO.jl. But how do we do that here, when we don't know the sizes of x and y in the setup method? The answer is we implement an OpenMDAOCore.setup_partials method, which gives us another chance to create more PartialsData structs after OpenMDAO has figured out what the sizes of all the inputs and outputs are:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"function OpenMDAOCore.setup_partials(self::ECompShapeByConn, input_sizes, output_sizes)\n    @assert input_sizes[\"x\"] == output_sizes[\"y\"]\n    m, n = input_sizes[\"x\"]\n    rows, cols = OpenMDAOCore.get_rows_cols(ss_sizes=Dict(:i=>m, :j=>n), of_ss=[:i, :j], wrt_ss=[:i, :j])\n    partials_data = [OpenMDAOCore.PartialsData(\"y\", \"x\"; rows=rows, cols=cols)]\n\n    return self, partials_data\nend","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"The OpenMDAOCore.setup_partials method will always take an instance of the OpenMDAOCore.AbstractComp (called self here), and two Dicts, both with String keys and NTuple{N, Int} values. The keys indicate the name of an input or output variable, and the NTuple{Int, N} values are the shapes of each variable. The first Dict holds all the input shapes, and the second Dict has all the output shapes.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Now, the job of setup_partials is to return two things:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"an <:AbstractComp that will be used with the OpenMDAO `Component\na Vector of PartialsData structs that describes the sparsity of each sub-Jacobian","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"(The setup_partials function needs to return an <:AbstractComp to support cases where the internals of the <:AbstractComp need to be updated base in the input and output variable sizes.) We'd like to include the rows and cols arguments to the PartialsData struct for the derivative of y with respect to x, but it's a bit tricky, since x and y are two-dimensional. Luckily, there is a small utility function provided by OpenMDAOCore.jl called get_rows_cols that can help us.","category":"page"},{"location":"shape_by_conn/#Sparsity-Patterns-with-get_rows_cols","page":"Variable Shapes at Runtime","title":"Sparsity Patterns with get_rows_cols","text":"","category":"section"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"The get_rows_cols function uses a symbolic notation to express sparsity patterns in a simple way. Here's an example that corresponds to our present case. Let's say x and y have shape (2, 3). Then the non-zero index combinations for the derivative of y with respect to x will be (using zero-based indices, which is what OpenMDAO expects for the rows and cols arguments):","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"y indices:  x indices:\n(0, 0)      (0, 0)\n(0, 1)      (0, 1)\n(0, 2)      (0, 2)\n(1, 0)      (1, 0)\n(1, 1)      (1, 1)\n(1, 2)      (1, 2)","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"So that table says that the value of y[0, 0] depends on x[0, 0] only, and the value of y[1, 0] depends on x[1, 0] only, etc.. But OpenMDAO expects flattened indices for the rows and cols arguments, not multi-dimensional indices. So we need to convert the multi-dimensional indices in that table to flattened ones. get_rows_cols does that for you, but if you wanted to do that by hand, what I usually do is think of an array having the same shape as each input or output, with each entry in the array corresponding to the entry's flat index. So for x and y, that would be:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"x_flat_indices =\n[0 1 2;\n 3 4 5]\n\ny_flat_indices =\n[0 1 2;\n 3 4 5]","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"(Remember that Python/NumPy arrays use row-major aka C ordering by default.) So we can now use those two arrays to translate the y indices and x indices from multi-dimensional to flat:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"y indices     x indices\nmulti, flat:  multi, flat:\n(0, 0) 0      (0, 0) 0\n(0, 1) 1      (0, 1) 1\n(0, 2) 2      (0, 2) 2\n(1, 0) 3      (1, 0) 3\n(1, 1) 4      (1, 1) 4\n(1, 2) 5      (1, 2) 5","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"So the rows and cols arguments will be","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"rows = [0, 1, 2, 3, 4, 5]\ncols = [0, 1, 2, 3, 4, 5]","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"where rows is the flat non-zero indices for y, and cols is the flat non-zero indices for x.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Now, how do we do this with get_rows_cols? First we have to assign labels to each dimension of y and x. The labels must be Symbols, and can be anything (but I usually use index-y things like :i, :j, :k, etc.). We express the sparsity pattern through the choice of labels. If we use a label for an output dimension that is also used for an input dimension, then we are saying that, for a given index i in the \"shared\" dimension, the value of the output at that index i depends on the value of the input index i along the labeled dimension, and no others. For example, if we had a one-dimensional y that was calculated from a one-dimensional x in this way:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"for i in 1:10\n    y[i] = sin(x[i])\nend","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"then we would use the same label for the (single) output and input dimension.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"For the present example, we could assign i and j (say) to the first and second dimensions, respectively, of both y and x, since y[i,j] only depends on x[i,j] for all valid i and j. We call these of_ss (short for \"of subscripts for the output) and wrt_ss (\"with respect to subscripts\").","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"of_ss = [:i, :j]\nwrt_ss = [:i, :j]","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"After deciding on the dimension labels, the only other thing we need to do is create a Dict that maps the dimension labels to their sizes:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"ss_sizes = Dict(:i=>2, :j=>3)","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"since, in our example, the first dimension of x and y has size 2, and the second, 3.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Then we pass those three things to get_rows_cols, which then returns the rows and cols we want.","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"rows, cols = OpenMDAOCore.get_rows_cols(; ss_sizes, of_ss, wrt_ss)","category":"page"},{"location":"shape_by_conn/#Back-to-the-Simple-Example","page":"Variable Shapes at Runtime","title":"Back to the Simple Example","text":"","category":"section"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Now, back to the simple example. Remember, we're trying to compute y = 2*x^2 + 1 elementwise for a 2D x and y. The compute! method is pretty straight-forward:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"function OpenMDAOCore.compute!(self::ECompShapeByConn, inputs, outputs)\n    x = inputs[\"x\"]\n    y = outputs[\"y\"]\n    y .= 2 .* x.^2 .+ 1\n    return nothing\nend","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Now, for the compute_partials! method, we have to be a bit tricky about the shape of the Jacobian of y with respect to x. The get_rows_cols function orders the rows and cols in such a way that the Jacobian gets allocated by OpenMDAO with shape (i, j), and is then flattened. Since NumPy arrays are row-major ordered, then, we need to reshape the Jacobian in the opposite order, then switch the dimensions. This is optional, but makes things easier:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"function OpenMDAOCore.compute_partials!(self::ECompShapeByConn, inputs, partials)\n    x = inputs[\"x\"]\n    m, n = size(x)\n    # So, with the way I've declared the partials above, OpenMDAO will have\n    # created a Numpy array of shape (m, n) and then flattened it. So, to get\n    # that to work, I'll need to do this:\n    dydx = PermutedDimsArray(reshape(partials[\"y\", \"x\"], n, m), (2, 1))\n    dydx .= 4 .* x\n    return nothing\nend","category":"page"},{"location":"shape_by_conn/#Checking","page":"Variable Shapes at Runtime","title":"Checking","text":"","category":"section"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Now, let's actually create a Problem with the new Component, along with an IndepVarComp that will actually decide on the size:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"using OpenMDAO, PythonCall\n\nm, n = 3, 4\np = om.Problem()\ncomp = om.IndepVarComp()\ncomp.add_output(\"x\", shape=(m, n))\np.model.add_subsystem(\"inputs_comp\", comp, promotes_outputs=[\"x\"])\n\necomp = ECompShapeByConn()\ncomp = make_component(ecomp)\np.model.add_subsystem(\"ecomp\", comp, promotes_inputs=[\"x\"], promotes_outputs=[\"y\"])\np.setup(force_alloc_complex=true)","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Now we should be able to check that the output we get is correct:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"p.set_val(\"x\", 1:m*n)\np.run_model()\n\n# Test that the output is what we expect.\nexpected = 2 .* PyArray(p.get_val(\"x\")).^2 .+ 1\nactual = PyArray(p.get_val(\"y\"))\nprintln(\"expected = $(expected)\")\nprintln(\"actual   = $(actual)\")","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"And we can check the derivatives:","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"p.check_partials(method=\"cs\")\nnothing","category":"page"},{"location":"shape_by_conn/","page":"Variable Shapes at Runtime","title":"Variable Shapes at Runtime","text":"Looks good!","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"brachistochrone/#A-Simple-Dymos-Example","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"","category":"section"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"We can also use OpenMDAO.jl Components within a Dymos ODE. This example will implement the Brachistochrone example from the Dymos docs using Julia.","category":"page"},{"location":"brachistochrone/#Preamble","page":"A Simple Dymos Example","title":"Preamble","text":"","category":"section"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"Let's make things easier on ourselves and import the VarData and PartialsData names into our local namespace:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"using OpenMDAOCore: OpenMDAOCore, VarData, PartialsData","category":"page"},{"location":"brachistochrone/#The-AbstractExplicitComp-struct","page":"A Simple Dymos Example","title":"The AbstractExplicitComp struct","text":"","category":"section"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"The ODE component for the brachistochrone has two options:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"num_nodes, the number of nodes used to descritize the trajectory of the bead.\nstatic_gravity, a flag to indicate whether gravity should vary along the trajectory (and thus have length num_nodes) or if it should be constant (and thus be a scalar).","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"We'll use a default value of false for static_gravity, just like the Python implementation in the Dymos docs:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"struct BrachistochroneODE <: OpenMDAOCore.AbstractExplicitComp\n    num_nodes::Int\n    static_gravity::Bool\nend\n\n# `static_gravity` set to `false` by default.\nBrachistochroneODE(; num_nodes, static_gravity=false) = BrachistochroneODE(num_nodes, static_gravity)","category":"page"},{"location":"brachistochrone/#OpenMDAOCore.setup","page":"A Simple Dymos Example","title":"OpenMDAOCore.setup","text":"","category":"section"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"Next we'll define the OpenMDAOCore.setup function:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"function OpenMDAOCore.setup(self::BrachistochroneODE)\n\tnn = self.num_nodes\n\n\t# Inputs\n    input_data = Vector{VarData}()\n    push!(input_data, VarData(\"v\"; val=zeros(nn), units=\"m/s\"))\n\tif self.static_gravity\n        push!(input_data, VarData(\"g\", val=9.80665, units=\"m/s/s\", tags=[\"dymos.static_target\"]))\n\telse\n        push!(input_data, VarData(\"g\", val=9.80665 * ones(nn), units=\"m/s/s\"))\n    end\n    push!(input_data, VarData(\"theta\", val=ones(nn), units=\"rad\"))\n\n    # Outputs\n    output_data = Vector{VarData}()\n    push!(output_data, VarData(\"xdot\", val=zeros(nn), units=\"m/s\", tags=[\"dymos.state_rate_source:x\", \"dymos.state_units:m\"]))\n    push!(output_data, VarData(\"ydot\", val=zeros(nn), units=\"m/s\", tags=[\"dymos.state_rate_source:y\", \"dymos.state_units:m\"]))\n    push!(output_data, VarData(\"vdot\", val=zeros(nn), units=\"m/s**2\", tags=[\"dymos.state_rate_source:v\", \"dymos.state_units:m/s\"]))\n    push!(output_data, VarData(\"check\", val=zeros(nn), units=\"m/s\"))\n\n    # Setup partials\n    arange = 0:nn-1\n    partials_data = Vector{PartialsData}()\n    push!(partials_data, PartialsData(\"vdot\", \"theta\"; rows=arange, cols=arange))\n\n    push!(partials_data, PartialsData(\"xdot\", \"v\"; rows=arange, cols=arange))\n    push!(partials_data, PartialsData(\"xdot\", \"theta\"; rows=arange, cols=arange))\n\n    push!(partials_data, PartialsData(\"ydot\", \"v\"; rows=arange, cols=arange))\n    push!(partials_data, PartialsData(\"ydot\", \"theta\"; rows=arange, cols=arange))\n\n    push!(partials_data, PartialsData(\"check\", \"v\"; rows=arange, cols=arange))\n    push!(partials_data, PartialsData(\"check\", \"theta\"; rows=arange, cols=arange))\n\n\tif self.static_gravity\n\t\tc = zeros(Int, self.num_nodes)\n        push!(partials_data, PartialsData(\"vdot\", \"g\"; rows=arange, cols=c))\n\telse\n        push!(partials_data, PartialsData(\"vdot\", \"g\"; rows=arange, cols=arange))\n    end\n\n    return input_data, output_data, partials_data\nend","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"This is probably the most complicated setup we've seen yet. A few things to note:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"We can change the size of the g (gravity) input and its sub-Jacobian using the static_gravity option in the BrachistochroneODE struct.\nThe VarData calls use tags, which are passed to the ExplicitComponent.add_input method using the tags keyword argument in OpenMDAO.\nAs we'll see, the job of a Dymos ODE is to compute the state rates from the states and controls. It turns out that in many (all) ODEs, these state rates for a given trajectory node only depend on the state and controls at that particular node. This implies that the Jacobian of the ODE calculation will be sparse. This example, like the original Python implementation, passes the sparsity pattern of the various sub-Jacobians to the PartialsData structs using the rows and cols keywords.","category":"page"},{"location":"brachistochrone/#OpenMDAOCore.compute!-and-OpenMDAOCore.compute_partials!","page":"A Simple Dymos Example","title":"OpenMDAOCore.compute! and OpenMDAOCore.compute_partials!","text":"","category":"section"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"The OpenMDAOCore.compute! method for our ODE is fairly straightforward:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"function OpenMDAOCore.compute!(self::BrachistochroneODE, inputs, outputs)\n\ttheta = inputs[\"theta\"]\n\tcos_theta = cos.(theta)\n\tsin_theta = sin.(theta)\n\tg = inputs[\"g\"]\n\tv = inputs[\"v\"]\n\n\t@. outputs[\"vdot\"] = g * cos_theta\n\t@. outputs[\"xdot\"] = v * sin_theta\n\t@. outputs[\"ydot\"] = -v * cos_theta\n\t@. outputs[\"check\"] = v / sin_theta\n\n    return nothing\nend","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"The @. macro tells Julia to use broadcasting for the array calculations (similar to NumPy broadcasting).","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"The compute_partials! method is also quite similar to the original Python implementation:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"function OpenMDAOCore.compute_partials!(self::BrachistochroneODE, inputs, partials)\n\ttheta = inputs[\"theta\"]\n\tcos_theta = cos.(theta)\n\tsin_theta = sin.(theta)\n\tg = inputs[\"g\"]\n\tv = inputs[\"v\"]\n\n\t@. partials[\"vdot\", \"g\"] = cos_theta\n\t@. partials[\"vdot\", \"theta\"] = -g * sin_theta\n\n\t@. partials[\"xdot\", \"v\"] = sin_theta\n\t@. partials[\"xdot\", \"theta\"] = v * cos_theta\n\n\t@. partials[\"ydot\", \"v\"] = -cos_theta\n\t@. partials[\"ydot\", \"theta\"] = v * sin_theta\n\n\t@. partials[\"check\", \"v\"] = 1 / sin_theta\n\t@. partials[\"check\", \"theta\"] = -v * cos_theta / sin_theta ^ 2\n\n\treturn nothing\nend","category":"page"},{"location":"brachistochrone/#The-run-script","page":"A Simple Dymos Example","title":"The run script","text":"","category":"section"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"We'll need the Dymos library to solve the Brachistochrone problem, of course:","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"using PythonCall: pyimport\ndm = pyimport(\"dymos\")","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"And then the rest of the script will be pretty much identical to the Python version, but written in Julia. We'll put it in a function that allows us to try out static_gravity=false and static_gravity=true.","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"using OpenMDAO: om, make_component  #, DymosifiedCompWrapper\n\nfunction doit(; static_gravity)\n  #\n  # Initialize the Problem and the optimization driver\n  #\n  p = om.Problem(model=om.Group())\n  p.driver = om.ScipyOptimizeDriver()\n  p.driver.declare_coloring()\n  #\n  # Create a trajectory and add a phase to it\n  #\n  traj = p.model.add_subsystem(\"traj\", dm.Trajectory())\n\n  # `Trajectory.add_phase` expects a class that it can instantiate with the number of nodes used for the phase.\n  # That's easy enough to create with an anonymous function, where we create a function that takes the single keyword argument `num_nodes`, use that to create a `BrachistochroneODE` with the appropriate value for `static_gravity`, and then pass that to the `make_component` function that returns an OpenMDAO `Component`.\n  phase = traj.add_phase(\"phase0\",\n                         dm.Phase(ode_class = (; num_nodes)->make_component(BrachistochroneODE(; num_nodes=num_nodes, static_gravity=static_gravity)),\n                                  transcription = dm.GaussLobatto(num_segments=10)))\n\n  #\n  # Set the variables\n  #\n  phase.set_time_options(fix_initial=true, duration_bounds=(.5, 10))\n\n  phase.add_state(\"x\", fix_initial=true, fix_final=true)\n\n  phase.add_state(\"y\", fix_initial=true, fix_final=true)\n\n  phase.add_state(\"v\", fix_initial=true, fix_final=false)\n\n  phase.add_control(\"theta\", continuity=true, rate_continuity=true,\n                    units=\"deg\", lower=0.01, upper=179.9)\n\n  phase.add_parameter(\"g\", units=\"m/s**2\", val=9.80665)\n\n  #\n  # Minimize time at the end of the phase\n  #\n  phase.add_objective(\"time\", loc=\"final\", scaler=10)\n  # \n  p.model.linear_solver = om.DirectSolver()\n  #\n  # Setup the Problem\n  #\n  p.setup()\n\n  #\n  # Set the initial values\n  #\n  p[\"traj.phase0.t_initial\"] = 0.0\n  p[\"traj.phase0.t_duration\"] = 2.0\n\n  p.set_val(\"traj.phase0.states:x\", phase.interp(\"x\", ys=[0, 10]))\n  p.set_val(\"traj.phase0.states:y\", phase.interp(\"y\", ys=[10, 5]))\n  p.set_val(\"traj.phase0.states:v\", phase.interp(\"v\", ys=[0, 9.9]))\n  p.set_val(\"traj.phase0.controls:theta\", phase.interp(\"theta\", ys=[5, 100.5]))\n\n  #\n  # Solve for the optimal trajectory\n  #\n  dm.run_problem(p)\n\n  # Check the results\n  println(\"static_gravity = $static_gravity, elapsed time = $(p.get_val(\"traj.phase0.timeseries.time\")[-1]) (should be 1.80164719)\")\nend\n\ndoit(; static_gravity=false)\ndoit(; static_gravity=true)","category":"page"},{"location":"brachistochrone/","page":"A Simple Dymos Example","title":"A Simple Dymos Example","text":"At the end we see we got pretty much the same answer for the elapsed time as the Python example in the Dymos docs. (But not exactly the same, which is a bummer...)","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"limitations/#Limitations","page":"Limitations","title":"Limitations","text":"","category":"section"},{"location":"limitations/#Import-juliacall-first-from-Python...-sometimes","page":"Limitations","title":"Import juliacall first from Python... sometimes","text":"","category":"section"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"When using the omjlcomps Python library, it is sometimes necessary to import juliacall before other Python libraries (at least matplotlib, maybe others too) to avoid an error that looks like this:","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"$ cat test.py\nimport matplotlib\nimport juliacall\n$ python test.py\nERROR: `ccall` requires the compilerTraceback (most recent call last):\n  File \"/home/dingraha/desk/pythoncall_wtf/test.py\", line 2, in <module>\n    import juliacall\n  File \"/home/dingraha/desk/pythoncall_wtf/venv-mybuild-with-libc-enable-shared-without-lto-without-optimizations-computed-gotos-no-dtrace-no-ssl/lib/python3.9/site-packages/juliacall/__init__.py\", line 218, in <module>\n    init()\n  File \"/home/dingraha/desk/pythoncall_wtf/venv-mybuild-with-libc-enable-shared-without-lto-without-optimizations-computed-gotos-no-dtrace-no-ssl/lib/python3.9/site-packages/juliacall/__init__.py\", line 214, in init\n    raise Exception('PythonCall.jl did not start properly')\nException: PythonCall.jl did not start properly\n$","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"This only occurs when using the system Python on certain Linux distributions (e.g., Python 3.9.7 on Red Hat Enterprise Linux 8.6). I've found three workarounds:","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"import the juliacall module first in your run script, before anything else, or\ndon't use the system Python: set up a Conda environment instead, or\ndon't use RHEL (the system Python on e.g. Arch Linux doesn't appear to suffer from this bug).","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"See this PythonCall issue for a few more details.","category":"page"},{"location":"limitations/#OpenMDAOCore.jl-must-be-explicitly-installed-in-Julia-projects/environments-that-use-OpenMDAO.jl","page":"Limitations","title":"OpenMDAOCore.jl must be explicitly installed in Julia projects/environments that use OpenMDAO.jl","text":"","category":"section"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"OpenMDAO.jl does something strange in its __init__: it calls Pkg.add(\"OpenMDAOCore\"), which has the effect of explicitly installing OpenMDAOCore.jl in the current Julia project/environment. Why? Well, let's remove that call, install OpenMDAO.jl in a fresh environment, and see what happens.","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"shell> mkdir MyNewEnvironment\n\nshell> cd MyNewEnvironment/\n/home/dingraha/Desktop/MyNewEnvironment\n\n(blah) pkg> activate .\n  Activating new project at `~/Desktop/MyNewEnvironment`\n\n(MyNewEnvironment) pkg> status\nStatus `~/Desktop/MyNewEnvironment/Project.toml` (empty project)\n\n(MyNewEnvironment) pkg> dev --local OpenMDAO\n     Cloning git-repo `https://github.com/byuflowlab/OpenMDAO.jl.git`\n   Resolving package versions...\n    Updating `~/Desktop/MyNewEnvironment/Project.toml`\n  [2d3f9b48] + OpenMDAO v0.4.1 `dev/OpenMDAO/julia/OpenMDAO.jl`\n    Updating `~/Desktop/MyNewEnvironment/Manifest.toml`\n  [992eb4ea] + CondaPkg v0.2.28\n  [9a962f9c] + DataAPI v1.16.0\n  [e2d170a0] + DataValueInterfaces v1.0.0\n  [82899510] + IteratorInterfaceExtensions v1.0.0\n  [692b3bcd] + JLLWrappers v1.7.0\n  [0f8b85d8] + JSON3 v1.14.2\n  [1914dd2f] + MacroTools v0.5.16\n  [0b3b1443] + MicroMamba v0.1.14\n  [2d3f9b48] + OpenMDAO v0.4.1 `dev/OpenMDAO/julia/OpenMDAO.jl`\n  [24d19c10] + OpenMDAOCore v0.3.1\n  [bac558e1] + OrderedCollections v1.8.0\n  [69de0a69] + Parsers v2.8.3\n  [fa939f87] + Pidfile v1.3.0\n⌅ [aea7be01] + PrecompileTools v1.2.1\n  [21216c6a] + Preferences v1.4.3\n  [6099a3de] + PythonCall v0.9.24\n  [ae029012] + Requires v1.3.1\n  [6c6a2e73] + Scratch v1.2.1\n  [856f2bd8] + StructTypes v1.11.0\n  [3783bdb8] + TableTraits v1.0.1\n  [bd369af6] + Tables v1.12.0\n  [e17b2a0c] + UnsafePointers v1.0.0\n  [f8abcde7] + micromamba_jll v1.5.8+0\n  [4d7b5844] + pixi_jll v0.41.3+0\n  [0dad84c5] + ArgTools v1.1.2\n  [56f22d72] + Artifacts v1.11.0\n  [2a0f44e3] + Base64 v1.11.0\n  [ade2ca70] + Dates v1.11.0\n  [f43a241f] + Downloads v1.6.0\n  [7b1f6079] + FileWatching v1.11.0\n  [b77e0a4c] + InteractiveUtils v1.11.0\n  [4af54fe1] + LazyArtifacts v1.11.0\n  [b27032c2] + LibCURL v0.6.4\n  [76f85450] + LibGit2 v1.11.0\n  [8f399da3] + Libdl v1.11.0\n  [56ddb016] + Logging v1.11.0\n  [d6f4376e] + Markdown v1.11.0\n  [a63ad114] + Mmap v1.11.0\n  [ca575930] + NetworkOptions v1.2.0\n  [44cfe95a] + Pkg v1.11.0\n  [de0858da] + Printf v1.11.0\n  [9a3f8284] + Random v1.11.0\n  [ea8e919c] + SHA v0.7.0\n  [9e88b42a] + Serialization v1.11.0\n  [fa267f1f] + TOML v1.0.3\n  [a4e569a6] + Tar v1.10.0\n  [8dfed614] + Test v1.11.0\n  [cf7118a7] + UUIDs v1.11.0\n  [4ec0a83e] + Unicode v1.11.0\n  [deac9b47] + LibCURL_jll v8.6.0+0\n  [e37daf67] + LibGit2_jll v1.7.2+0\n  [29816b5a] + LibSSH2_jll v1.11.0+1\n  [c8ffd9c3] + MbedTLS_jll v2.28.6+0\n  [14a3606d] + MozillaCACerts_jll v2023.12.12\n  [83775a58] + Zlib_jll v1.2.13+1\n  [8e850ede] + nghttp2_jll v1.59.0+0\n  [3f19e933] + p7zip_jll v17.4.0+2\n        Info Packages marked with ⌅ have new versions available but compatibility constraints restrict them from upgrading. To see why use `s\ntatus --outdated -m`\n\nshell> nvr ./dev/OpenMDAO/julia/OpenMDAO.jl/src/OpenMDAO.jl # edit OpenMDAO.jl, removing `Pkg.add(\"OpenMDAOCore\")`\n\n(MyNewEnvironment) pkg> status\nStatus `~/Desktop/MyNewEnvironment/Project.toml`\n  [2d3f9b48] OpenMDAO v0.4.1 `dev/OpenMDAO/julia/OpenMDAO.jl`\n\njulia> using OpenMDAO\nPrecompiling OpenMDAO...\nInfo Given OpenMDAO was explicitly requested, output will be shown live \n    CondaPkg Found dependencies: /home/dingraha/.julia/packages/PythonCall/WMWY0/CondaPkg.toml\n    CondaPkg Found dependencies: /home/dingraha/Desktop/MyNewEnvironment/dev/OpenMDAO/julia/OpenMDAO.jl/CondaPkg.toml\n    CondaPkg Resolving changes\n             + juliapkg (pip)\n             + libstdcxx-ng\n             + omjlcomps (pip)\n             + openmdao\n             + python\n             + uv\n    CondaPkg Initialising pixi\n             │ /home/dingraha/.julia/artifacts/cefba4912c2b400756d043a2563ef77a0088866b/bin/pixi\n             │ init\n             │ --format pixi\n             └ /home/dingraha/Desktop/MyNewEnvironment/.CondaPkg\n✔ Created /home/dingraha/Desktop/MyNewEnvironment/.CondaPkg/pixi.toml\n    CondaPkg Wrote /home/dingraha/Desktop/MyNewEnvironment/.CondaPkg/pixi.toml\n             │ [dependencies]\n             │ uv = \">=0.4\"\n             │ libstdcxx-ng = \">=3.4,<13.0\"\n             │ openmdao = \">=3.26.0,<4\"\n             │ \n             │     [dependencies.python]\n             │     channel = \"conda-forge\"\n             │     build = \"*cpython*\"\n             │     version = \">=3.8,<4\"\n             │ \n             │ [project]\n             │ name = \".CondaPkg\"\n             │ platforms = [\"linux-64\"]\n             │ channels = [\"conda-forge\"]\n             │ channel-priority = \"strict\"\n             │ description = \"automatically generated by CondaPkg.jl\"\n             │ \n             │ [pypi-dependencies]\n             │ juliapkg = \"~=0.1.10\"\n             └ omjlcomps = \"~=0.2.0\"\n    CondaPkg Installing packages\n             │ /home/dingraha/.julia/artifacts/cefba4912c2b400756d043a2563ef77a0088866b/bin/pixi\n             │ install\n             └ --manifest-path /home/dingraha/Desktop/MyNewEnvironment/.CondaPkg/pixi.toml\n✔ The default environment has been installed.\n  4 dependencies successfully precompiled in 24 seconds. 48 already precompiled.\n  1 dependency had output during precompilation:\n┌ OpenMDAO\n│  [Output was shown above]\n└  \nERROR: InitError: Python: Julia: ArgumentError: Package OpenMDAOCore not found in current path.\n- Run `import Pkg; Pkg.add(\"OpenMDAOCore\")` to install the OpenMDAOCore package.\nStacktrace:\n  [1] macro expansion\n    @ ./loading.jl:2296 [inlined]\n  [2] macro expansion\n    @ ./lock.jl:273 [inlined]\n  [3] __require(into::Module, mod::Symbol)\n    @ Base ./loading.jl:2271\n  [4] #invoke_in_world#3\n    @ ./essentials.jl:1089 [inlined]\n  [5] invoke_in_world\n    @ ./essentials.jl:1086 [inlined]\n  [6] require(into::Module, mod::Symbol)\n    @ Base ./loading.jl:2260\n  [7] eval\n    @ ./boot.jl:430 [inlined]\n  [8] eval\n    @ ./Base.jl:130 [inlined]\n  [9] pyjlmodule_seval(self::Module, expr::PythonCall.Core.Py)\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/WMWY0/src/JlWrap/module.jl:13\n [10] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/WMWY0/src/JlWrap/base.jl:67\n [11] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\n    @ PythonCall.JlWrap.Cjl ~/.julia/packages/PythonCall/WMWY0/src/JlWrap/C.jl:63\n [12] PyImport_Import\n    @ ~/.julia/packages/PythonCall/WMWY0/src/C/pointers.jl:303 [inlined]\n [13] macro expansion\n    @ ~/.julia/packages/PythonCall/WMWY0/src/Core/Py.jl:132 [inlined]\n [14] pyimport(m::String)\n    @ PythonCall.Core ~/.julia/packages/PythonCall/WMWY0/src/Core/builtins.jl:1561\n [15] __init__()\n    @ OpenMDAO ~/Desktop/MyNewEnvironment/dev/OpenMDAO/julia/OpenMDAO.jl/src/OpenMDAO.jl:16\n [16] run_module_init(mod::Module, i::Int64)\n    @ Base ./loading.jl:1378\n [17] register_restored_modules(sv::Core.SimpleVector, pkg::Base.PkgId, path::String)\n    @ Base ./loading.jl:1366\n [18] _include_from_serialized(pkg::Base.PkgId, path::String, ocachepath::String, depmods::Vector{Any}, ignore_native::Nothing; register::Boo\nl)\n    @ Base ./loading.jl:1254\n [19] _include_from_serialized (repeats 2 times)\n    @ ./loading.jl:1210 [inlined]\n [20] _require_search_from_serialized(pkg::Base.PkgId, sourcepath::String, build_id::UInt128, stalecheck::Bool; reasons::Dict{…}, DEPOT_PATH:\n:Vector{…})\n    @ Base ./loading.jl:2057\n [21] _require(pkg::Base.PkgId, env::String)\n    @ Base ./loading.jl:2527\n [22] __require_prelocked(uuidkey::Base.PkgId, env::String)\n    @ Base ./loading.jl:2388\n [23] #invoke_in_world#3\n    @ ./essentials.jl:1089 [inlined]\n [24] invoke_in_world\n    @ ./essentials.jl:1086 [inlined]\n [25] _require_prelocked(uuidkey::Base.PkgId, env::String)\n    @ Base ./loading.jl:2375\n [26] macro expansion\n    @ ./loading.jl:2314 [inlined]\n [27] macro expansion\n    @ ./lock.jl:273 [inlined]\n [28] __require(into::Module, mod::Symbol)\n    @ Base ./loading.jl:2271\n [29] #invoke_in_world#3\n    @ ./essentials.jl:1089 [inlined]\n [30] invoke_in_world\n    @ ./essentials.jl:1086 [inlined]\n [31] require(into::Module, mod::Symbol)\n    @ Base ./loading.jl:2260\n [32] eval\n    @ ./boot.jl:430 [inlined]\n [33] eval_user_input(ast::Any, backend::REPL.REPLBackend, mod::Module)\n    @ REPL ~/local/julia/1.11.5/share/julia/stdlib/v1.11/REPL/src/REPL.jl:261\n [34] repl_backend_loop(backend::REPL.REPLBackend, get_module::Function)\n    @ REPL ~/local/julia/1.11.5/share/julia/stdlib/v1.11/REPL/src/REPL.jl:368\n [35] start_repl_backend(backend::REPL.REPLBackend, consumer::Any; get_module::Function)\n    @ REPL ~/local/julia/1.11.5/share/julia/stdlib/v1.11/REPL/src/REPL.jl:343\n [36] run_repl(repl::REPL.AbstractREPL, consumer::Any; backend_on_current_task::Bool, backend::Any)\n    @ REPL ~/local/julia/1.11.5/share/julia/stdlib/v1.11/REPL/src/REPL.jl:500\n [37] run_repl(repl::REPL.AbstractREPL, consumer::Any)\n    @ REPL ~/local/julia/1.11.5/share/julia/stdlib/v1.11/REPL/src/REPL.jl:486\n [38] (::Base.var\"#1150#1152\"{Bool, Symbol, Bool})(REPL::Module)\n    @ Base ./client.jl:446\n [39] #invokelatest#2\n    @ ./essentials.jl:1055 [inlined]\n [40] invokelatest\n    @ ./essentials.jl:1052 [inlined]\n [41] run_main_repl(interactive::Bool, quiet::Bool, banner::Symbol, history_file::Bool, color_set::Bool)\n    @ Base ./client.jl:430\n [42] repl_main\n    @ ./client.jl:567 [inlined]\n [43] _start()\n    @ Base ./client.jl:541\nPython stacktrace:\n [1] seval\n   @ ~/.julia/packages/PythonCall/WMWY0/src/JlWrap/module.jl:27\n [2] <module>\n   @ ~/Desktop/MyNewEnvironment/.CondaPkg/.pixi/envs/default/lib/python3.12/site-packages/omjlcomps/__init__.py:9\nStacktrace:\n  [1] pythrow()\n    @ PythonCall.Core ~/.julia/packages/PythonCall/WMWY0/src/Core/err.jl:92\n  [2] errcheck\n    @ ~/.julia/packages/PythonCall/WMWY0/src/Core/err.jl:10 [inlined]\n  [3] pyimport(m::String)\n    @ PythonCall.Core ~/.julia/packages/PythonCall/WMWY0/src/Core/builtins.jl:1561\n  [4] __init__()\n    @ OpenMDAO ~/Desktop/MyNewEnvironment/dev/OpenMDAO/julia/OpenMDAO.jl/src/OpenMDAO.jl:16\n  [5] run_module_init(mod::Module, i::Int64)\n    @ Base ./loading.jl:1378\n  [6] register_restored_modules(sv::Core.SimpleVector, pkg::Base.PkgId, path::String)\n    @ Base ./loading.jl:1366\n  [7] _include_from_serialized(pkg::Base.PkgId, path::String, ocachepath::String, depmods::Vector{Any}, ignore_native::Nothing; register::Boo\nl)\n    @ Base ./loading.jl:1254\n  [8] _include_from_serialized (repeats 2 times)\n    @ ./loading.jl:1210 [inlined]\n  [9] _require_search_from_serialized(pkg::Base.PkgId, sourcepath::String, build_id::UInt128, stalecheck::Bool; reasons::Dict{…}, DEPOT_PATH:\n:Vector{…})\n    @ Base ./loading.jl:2057\n [10] _require(pkg::Base.PkgId, env::String)\n    @ Base ./loading.jl:2527\n [11] __require_prelocked(uuidkey::Base.PkgId, env::String)\n    @ Base ./loading.jl:2388\n [12] #invoke_in_world#3\n    @ ./essentials.jl:1089 [inlined]\n [13] invoke_in_world\n    @ ./essentials.jl:1086 [inlined]\n [14] _require_prelocked(uuidkey::Base.PkgId, env::String)\n    @ Base ./loading.jl:2375\n [15] macro expansion\n    @ ./loading.jl:2314 [inlined]\n [16] macro expansion\n    @ ./lock.jl:273 [inlined]\n [17] __require(into::Module, mod::Symbol)\n    @ Base ./loading.jl:2271\n [18] #invoke_in_world#3\n    @ ./essentials.jl:1089 [inlined]\n [19] invoke_in_world\n    @ ./essentials.jl:1086 [inlined]\n [20] require(into::Module, mod::Symbol)\n    @ Base ./loading.jl:2260\nduring initialization of module OpenMDAO\nSome type information was truncated. Use `show(err)` to see complete types.\n\njulia> ","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"What happened there? We see from the output when installing OpenMDAO.jl that OpenMDAOCore.jl was installed, and when doing using OpenMDAO the Python environment was set up nicely for us, and did install the \"real\" Python OpenMDAO and omjlcomps packages for us. But then omjlcomps complains about not being able to find OpenMDAOCore, despite it being in the MyNewEnvironment Manifest.toml:","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"(MyNewEnvironment) pkg> status --manifest\nStatus `~/Desktop/MyNewEnvironment/Manifest.toml`\n  [992eb4ea] CondaPkg v0.2.28\n  [9a962f9c] DataAPI v1.16.0\n  [e2d170a0] DataValueInterfaces v1.0.0\n  [82899510] IteratorInterfaceExtensions v1.0.0\n  [692b3bcd] JLLWrappers v1.7.0\n  [0f8b85d8] JSON3 v1.14.2\n  [1914dd2f] MacroTools v0.5.16\n  [0b3b1443] MicroMamba v0.1.14\n  [2d3f9b48] OpenMDAO v0.4.1 `dev/OpenMDAO/julia/OpenMDAO.jl`\n  [24d19c10] OpenMDAOCore v0.3.1\n  [bac558e1] OrderedCollections v1.8.0\n  [69de0a69] Parsers v2.8.3\n  [fa939f87] Pidfile v1.3.0\n⌅ [aea7be01] PrecompileTools v1.2.1\n  [21216c6a] Preferences v1.4.3\n  [6099a3de] PythonCall v0.9.24\n  [ae029012] Requires v1.3.1\n  [6c6a2e73] Scratch v1.2.1\n  [856f2bd8] StructTypes v1.11.0\n  [3783bdb8] TableTraits v1.0.1\n  [bd369af6] Tables v1.12.0\n  [e17b2a0c] UnsafePointers v1.0.0\n  [f8abcde7] micromamba_jll v1.5.8+0\n  [4d7b5844] pixi_jll v0.41.3+0\n  [0dad84c5] ArgTools v1.1.2\n  [56f22d72] Artifacts v1.11.0\n  [2a0f44e3] Base64 v1.11.0\n  [ade2ca70] Dates v1.11.0\n  [f43a241f] Downloads v1.6.0\n  [7b1f6079] FileWatching v1.11.0\n  [b77e0a4c] InteractiveUtils v1.11.0\n  [4af54fe1] LazyArtifacts v1.11.0\n  [b27032c2] LibCURL v0.6.4\n  [76f85450] LibGit2 v1.11.0\n  [8f399da3] Libdl v1.11.0\n  [56ddb016] Logging v1.11.0\n  [d6f4376e] Markdown v1.11.0\n  [a63ad114] Mmap v1.11.0\n  [ca575930] NetworkOptions v1.2.0\n  [44cfe95a] Pkg v1.11.0\n  [de0858da] Printf v1.11.0\n  [9a3f8284] Random v1.11.0\n  [ea8e919c] SHA v0.7.0\n  [9e88b42a] Serialization v1.11.0\n  [fa267f1f] TOML v1.0.3\n  [a4e569a6] Tar v1.10.0\n  [8dfed614] Test v1.11.0\n  [cf7118a7] UUIDs v1.11.0\n  [4ec0a83e] Unicode v1.11.0\n  [deac9b47] LibCURL_jll v8.6.0+0\n  [e37daf67] LibGit2_jll v1.7.2+0\n  [29816b5a] LibSSH2_jll v1.11.0+1\n  [c8ffd9c3] MbedTLS_jll v2.28.6+0\n  [14a3606d] MozillaCACerts_jll v2023.12.12\n  [83775a58] Zlib_jll v1.2.13+1\n  [8e850ede] nghttp2_jll v1.59.0+0\n  [3f19e933] p7zip_jll v17.4.0+2\nInfo Packages marked with ⌅ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --\noutdated -m`\n\n(MyNewEnvironment) pkg> ","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"But, now, let's explicitly install OpenMDAOCore.jl:","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"(MyNewEnvironment) pkg> add OpenMDAOCore\n   Resolving package versions...\n    Updating `~/Desktop/MyNewEnvironment/Project.toml`\n  [24d19c10] + OpenMDAOCore v0.3.1\n  No Changes to `~/Desktop/MyNewEnvironment/Manifest.toml`\n\njulia> using OpenMDAO\n\njulia> ","category":"page"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"Now things seem to work! What's going on? I'm not entirely sure. For some reason, omjlcomps isn't able to find the OpenMDAOCore.jl that is installed by OpenMDAO.jl \"behind the scenes\" when it's a plain dependency, but can when it's explicitly installed. So, the Pkg.add(\"OpenMDAOCore\") call does this for us automatically. It will install the latest stable version of OpenMDAOCore.jl that's compatible with your environment. If you require a specific version of OpenMDAOCore.jl (eg you want to dev it while working on it), you'll need to install that in your environment in the usual way with Julia's package manager. (See also https://github.com/JuliaPy/CondaPkg.jl/issues/95)","category":"page"},{"location":"limitations/#Finding-juliapkg.json-files-in-editable-Python-packages","page":"Limitations","title":"Finding juliapkg.json files in editable Python packages","text":"","category":"section"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"juliapkg is the Python package that allows us to declare Julia dependencies in Python packages. We do this by including juliapkg.json files in our Python packages that describe the Julia dependencies. juliapkg will then look for these JSON files in, among other locations, \"every directory and direct sub-directory in sys.path. When installing Python packages in \"editable\" mode with pip install --editable or pip install -e, though, the package is generally not added to sys.path, and so juliapkg will not find juliapkg.json will not find the JSON file, not install the required Julia dependencies, and finally you'll expect to see errors where Julia complains that it can't find the Julia packages your code requires. A fix for this has been included in this PR, but in the meantime, the solution appears to be to install the editable Python package with pip install --config-settings editable_mode=compat -e <path to package>.","category":"page"},{"location":"limitations/#Distributing-Julia-files-in-a-Python-package","page":"Limitations","title":"Distributing Julia files in a Python package","text":"","category":"section"},{"location":"limitations/","page":"Limitations","title":"Limitations","text":"When creating a source distribution for a Python package, setuptools will only include certain files, and, perhaps not surprisingly, will ignore Julia files. The solution is to add a MANIFEST.in to the top-level of the Python package that includes all the Julia files you need. See the example package in examples for an... example of how to do this.","category":"page"},{"location":"reference/","page":"API Reference","title":"API Reference","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"reference/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"reference/","page":"API Reference","title":"API Reference","text":"Modules = [OpenMDAOCore, OpenMDAO]","category":"page"},{"location":"reference/#OpenMDAOCore.MatrixFreeADExplicitComp-Tuple{Any, Any, ComponentArrays.ComponentVector, ComponentArrays.ComponentVector}","page":"API Reference","title":"OpenMDAOCore.MatrixFreeADExplicitComp","text":"MatrixFreeADExplicitComp(ad_backend, f!, Y_ca::ComponentVector, X_ca::ComponentVector; params=nothing, force_mode=\"\", disable_prep=false, units_dict=Dict{Symbol,String}(), tags_dict=Dict{Symbol,Vector{String}}(), shape_by_conn_dict=Dict{Symbol,Bool}(), copy_shape_dict=Dict{Symbol,Symbol}(), aviary_input_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_output_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_meta_data=Dict{String,Any}())\n\nCreate a MatrixFreeADExplicitComp from a user-defined function and output and input ComponentVectors.\n\nPositional Arguments\n\nad_backend: <:ADTypes.AbstractADType automatic differentation \"backend\" library\nf!: function of the form f!(Y_ca, X_ca, params) which writes outputs to Y_ca using inputs X_ca and, optionally, parameters params.\nY_ca: ComponentVector of outputs\nX_ca: ComponentVector of inputs\n\nKeyword Arguments\n\nparams: parameters passed to the third argument to f!. Could be anything, or nothing, but the derivatives of Y_ca with respect to params will not be calculated\nforce_mode=\"\": If \"fwd\", use DifferentiationInterface.pushforward! to compute the derivatives (aka perform a Jacobian-vector product). If \"rev\", use DifferentiationInterface.pullback! to compute the derivatives (aka perform a vector-Jacobian product). If \"\", use whatever would be faster, as determined by DifferentiationInterface.pushforward_performance and DifferentiationInterface.pullback_performance, prefering pushforward.\ndisable_prep: if true, do not use either prepare_pushforward or prepare_pullback to create a DifferentiationInterface.PushforwardPrep or PullbackPrep object to accelerate the derivative calculation. Disabling prep can avoid correctness issues with ReverseDiff.jl, see the discussion of branching and the AbstractTape API.\nunits_dict: Dict mapping variable names (as Symbols) to OpenMDAO units (expressed as Strings)\ntags_dict: Dict mapping variable names (as Symbols) to Vectors of OpenMDAO tags\nshape_by_conn_dict: Dict mapping variable names (as Symbols) to Bools indicating if the variable's shape (size) will be set dynamically by a connection\ncopy_shape_dict: Dict mapping variable names to other variable names indicating the \"key\" symbol should take its size from the \"value\" symbol\naviary_input_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of input variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary input variables.\naviary_output_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of output variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary output variables.\naviary_meta_data::Dict{String,Any}: mapping of Aviary variable names to aviary metadata. Currently only the \"units\" and \"default_value\" fields are used.\n\n\n\n\n\n","category":"method"},{"location":"reference/#OpenMDAOCore.MatrixFreeADExplicitComp-Tuple{Any, Any, ComponentArrays.ComponentVector}","page":"API Reference","title":"OpenMDAOCore.MatrixFreeADExplicitComp","text":"MatrixFreeADExplicitComp(ad_backend, f, X_ca::ComponentVector; params=nothing, force_mode=\"\", disable_prep=false, units_dict=Dict{Symbol,String}(), tags_dict=Dict{Symbol,Vector{String}}(), shape_by_conn_dict=Dict{Symbol,Bool}(), copy_shape_dict=Dict{Symbol,Symbol}(), aviary_input_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_output_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_meta_data=Dict{String,Any}())\n\nCreate a MatrixFreeADExplicitComp from a user-defined function and output and input ComponentVectors.\n\nPositional Arguments\n\nad_backend: <:ADTypes.AbstractADType automatic differentation \"backend\" library\nf: function of the form Y_ca = f(X_ca, params) which returns outputs Y_ca using inputs X_ca and, optionally, parameters params.\nX_ca: ComponentVector of inputs\n\nKeyword Arguments\n\nparams: parameters passed to the third argument to f!. Could be anything, or nothing, but the derivatives of Y_ca with respect to params will not be calculated\nforce_mode=\"\": If \"fwd\", use DifferentiationInterface.pushforward! to compute the derivatives (aka perform a Jacobian-vector product). If \"rev\", use DifferentiationInterface.pullback! to compute the derivatives (aka perform a vector-Jacobian product). If \"\", use whatever would be faster, as determined by DifferentiationInterface.pushforward_performance and DifferentiationInterface.pullback_performance, prefering pushforward.\ndisable_prep: if true, do not use either prepare_pushforward or prepare_pullback to create a DifferentiationInterface.PushforwardPrep or PullbackPrep object to accelerate the derivative calculation. Disabling prep can avoid correctness issues with ReverseDiff.jl, see the discussion of branching and the AbstractTape API.\nunits_dict: Dict mapping variable names (as Symbols) to OpenMDAO units (expressed as Strings)\ntags_dict: Dict mapping variable names (as Symbols) to Vectors of OpenMDAO tags\nshape_by_conn_dict: Dict mapping variable names (as Symbols) to Bools indicating if the variable's shape (size) will be set dynamically by a connection\ncopy_shape_dict: Dict mapping variable names to other variable names indicating the \"key\" symbol should take its size from the \"value\" symbol\naviary_input_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of input variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary input variables.\naviary_output_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of output variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary output variables.\naviary_meta_data::Dict{String,Any}: mapping of Aviary variable names to aviary metadata. Currently only the \"units\" and \"default_value\" fields are used.\n\n\n\n\n\n","category":"method"},{"location":"reference/#OpenMDAOCore.PartialsData","page":"API Reference","title":"OpenMDAOCore.PartialsData","text":"PartialsData(of::String, wrt::String; <keyword arguments>)\n\nCreate a PartialsData object for the derivative of variable of with respect to variable wrt.\n\nPartialsData objects are used to construct arguments to OpenMDAO's Component.declare_partials method. Specifically, a PartialsData object pd will eventually be used to call Component.declare_partials like this:\n\nComponent.declare_partials(pd.of, pd.wrt, rows=pd.rows, cols=pd.cols, val=pd.val, method=pd.method)\n\nThe of and wrt positional arguments are required and set the of and wrt fields. The value of the other PartialsData fields (e.g., pd.rows, pd.val, etc.) are set via constructor keyword arguments, here:\n\nKeyword Arguments\n\nrows::Union{<:AbstractVector{Int64},Nothing} = nothing: row indices for each non-zero Jacobian entry, if not nothing.\ncols::Union{<:AbstractVector{Int64},Nothing} = nothing: column indices for each non-zero Jacobian entry, if not nothing.\nval::Union{Float64,<:AbstractArray{Float64},Nothing} = nothing: value of Jacobian, if not nothing.\nmethod::String = \"exact\": method use to calcluate the partial derivative(s). Should be one of\n\"exact\": user-defined partial derivatives via compute_partials!, linearize!, etc.\n\"fd\": finite difference approximation\n\"cs\": complex step approximation\n\n\n\n\n\n","category":"type"},{"location":"reference/#OpenMDAOCore.PerturbedDenseSparsityDetector","page":"API Reference","title":"OpenMDAOCore.PerturbedDenseSparsityDetector","text":"PerturbedDenseSparsityDetector\n\nTweaked version of DenseSparsityDetector sparsity pattern detector satisfying the detection API of ADTypes.jl that evaluates the Jacobian multiple times using a perturbed input vector. Specifically, input vector x will be perturbed via\n\n    x_perturb = (1 .+ rel_x_perturb.*perturb1).*x .+ perturb2.*abs_x_perturb\n\nwhere perturb1 and perturb2 are random Vectors of numbers ranging from -0.5 to 0.5, and rel_x_perturb and abs_x_perturb are relative and absolute perturbation magnitudes specified by the user.\n\nAll of the caveats associated with the performance of DenseSparsityDetector apply to PerturbedDenseSparsityDetector, since it essentially does the same thing as DenseSparsityDetector multiple times. The nonzeros in a Jacobian or Hessian are detected by computing the relevant matrix with dense AD, and thresholding the entries with a given tolerance (which can be numerically inaccurate). This process can be very slow, and should only be used if its output can be exploited multiple times to compute many sparse matrices.\n\ndanger: Danger\nIn general, the sparsity pattern you obtain can depend on the provided input x. If you want to reuse the pattern, make sure that it is input-agnostic. Perturbing the input vector should hopefully guard against getting \"unlucky\" and finding zero Jacobian entries that aren't actually zero for all x, but is of course problem-dependent.\n\nFields\n\nbackend::AbstractADType is the dense AD backend used under the hood\natol::Float64 is the minimum magnitude of a matrix entry to be considered nonzero\nnevals::Int=3 is the number of times the Jacobian will be evaluated using the perturbed input x\nrel_x_perturb=0.001: is the relative magnitude of the x perturbation.\n\nConstructor\n\nPerturbedDenseSparsityDetector(backend; atol, method=:iterative, nevals=3, rel_x_perturb=0.001, abs_x_perturb=0.0001)\n\nThe keyword argument method::Symbol can be either:\n\n:iterative: compute the matrix in a sequence of matrix-vector products (memory-efficient)\n:direct: compute the matrix all at once (memory-hungry but sometimes faster).\n\nNote that the constructor is type-unstable because method ends up being a type parameter of the PerturbedDenseSparsityDetector object (this is not part of the API and might change).\n\n\n\n\n\n","category":"type"},{"location":"reference/#OpenMDAOCore.SparseADExplicitComp","page":"API Reference","title":"OpenMDAOCore.SparseADExplicitComp","text":"SparseADExplicitComp{InPlace,TAD,TCompute,TX,TY,TJ,TPrep,TXCS,TYCS,TAMD} <: AbstractExplicitComp{InPlace}\n\nAn <:AbstractADExplicitComp for sparse Jacobians.\n\nFields\n\nad_backend::TAD: <:ADTypes.AutoSparse automatic differentation \"backend\" library\ncompute_adable::TCompute: function of the form compute_adable(Y, X) compatible with DifferentiationInterface.jl that performs the desired computation, where Y and X are ComponentVectors of outputs and inputs, respectively\nX_ca::ComponentVector: ComponentVector of inputs\nY_ca::ComponentVector: ComponentVector of outputs\nJ_ca_sparse::ComponentMatrix: Sparse ComponentMatrix of the Jacobian of Y_ca with respect to X_ca\nunits_dict::Dict{Symbol,String}: mapping of variable names to units. Can be an empty Dict if units are not desired.\ntags_dict::Dict{Symbol,Vector{String}: mapping of variable names to Vectors of Strings specifing variable tags.\nshape_by_conn_dict::Dict{Symbol,Bool}: mapping of variable names to Bool indicating if the variable shape should be determined dynamically by a connection.\naviary_input_names::Dict{Symbol,String}: mapping of input variable names to Aviary names.\naviary_output_names::Dict{Symbol,String}: mapping of output variable names to Aviary names.\naviary_meta_data::Dict{String,Any}: mapping of Aviary variable names to aviary metadata. Currently only the \"units\" and \"default_value\" fields are used.\nprep::DifferentiationInterface.JacobianPrep: DifferentiationInterface.jl \"preparation\" object\nrcdict: Dict{Tuple{Symbol,Sympol}, Tuple{Vector{Int}, Vector{Int}} mapping sub-Jacobians of the form (:output_name, :input_name) to Vectors of non-zero row and column indices (1-based)\nX_ca::ComponentVector: ComplexF64 version of X_ca (for the complex-step method)\nY_ca::ComponentVector: ComplexF64 version of Y_ca (for the complex-step method)\n\n\n\n\n\n","category":"type"},{"location":"reference/#OpenMDAOCore.SparseADExplicitComp-Union{Tuple{TAD}, Tuple{TAD, Any, ComponentArrays.ComponentVector, ComponentArrays.ComponentVector}} where TAD<:ADTypes.AutoSparse","page":"API Reference","title":"OpenMDAOCore.SparseADExplicitComp","text":"SparseADExplicitComp(ad_backend, f!, Y_ca::ComponentVector, X_ca::ComponentVector; params=nothing, units_dict=Dict{Symbol,String}(), tags_dict=Dict{Symbol,Vector{String}}(), shape_by_conn_dict=Dict{Symbol,Bool}(), copy_shape_dict=Dict{Symbol,Symbol}(), force_skip_prep=false, aviary_input_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_output_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_meta_data=Dict{String,Any}())\n\nCreate a SparseADExplicitComp from a user-defined function and output and input ComponentVectors.\n\nPositional Arguments\n\nad_backend: <:ADTypes.AutoSparse automatic differentation \"backend\" library\nf!: function of the form f!(Y_ca, X_ca, params) which writes outputs to Y_ca using inputs X_ca and, optionally, parameters params.\nY_ca: ComponentVector of outputs\nX_ca: ComponentVector of inputs\n\nKeyword Arguments\n\nparams: parameters passed to the third argument to f!. Could be anything, or nothing, but the derivatives of Y_ca with respect to params will not be calculated\nunits_dict: Dict mapping variable names (as Symbols) to OpenMDAO units (expressed as Strings)\ntags_dict: Dict mapping variable names (as Symbols) to Vectors of OpenMDAO tags\nshape_by_conn_dict: Dict mapping variable names (as Symbols) to Bools indicating if the variable's shape (size) will be set dynamically by a connection\ncopy_shape_dict: Dict mapping variable names to other variable names indicating the \"key\" symbol should take its size from the \"value\" symbol\nforce_skip_prep: if true, defer creating internal arrays and other structs until the user calls update_prep!\naviary_input_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of input variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary input variables.\naviary_output_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of output variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary output variables.\naviary_meta_data::Dict{String,Any}: mapping of Aviary variable names to aviary metadata. Currently only the \"units\" and \"default_value\" fields are used.\n\n\n\n\n\n","category":"method"},{"location":"reference/#OpenMDAOCore.SparseADExplicitComp-Union{Tuple{TAD}, Tuple{TAD, Any, ComponentArrays.ComponentVector}} where TAD<:ADTypes.AutoSparse","page":"API Reference","title":"OpenMDAOCore.SparseADExplicitComp","text":"SparseADExplicitComp(ad_backend, f, X_ca::ComponentVector; params=nothing, units_dict=Dict{Symbol,String}(), tags_dict=Dict{Symbol,Vector{String}}(), shape_by_conn_dict=Dict{Symbol,Bool}(), copy_shape_dict=Dict{Symbol,Symbol}(), force_skip_prep=false, aviary_input_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_output_vars=Dict{Symbol,Dict{String,<:Any}}(), aviary_meta_data=Dict{String,Any}())\n\nCreate a SparseADExplicitComp from a user-defined function and output and input ComponentVectors.\n\nPositional Arguments\n\nad_backend: <:ADTypes.AutoSparse automatic differentation \"backend\" library\nf: function of the form Y_ca = f(X_ca, params) which returns outputs Y_ca using inputs X_ca and, optionally, parameters params.\nX_ca: ComponentVector of inputs\n\nKeyword Arguments\n\nparams: parameters passed to the third argument to f!. Could be anything, or nothing, but the derivatives of Y_ca with respect to params will not be calculated\nunits_dict: Dict mapping variable names (as Symbols) to OpenMDAO units (expressed as Strings)\ntags_dict: Dict mapping variable names (as Symbols) to Vectors of OpenMDAO tags\nshape_by_conn_dict: Dict mapping variable names (as Symbols) to Bools indicating if the variable's shape (size) will be set dynamically by a connection\ncopy_shape_dict: Dict mapping variable names to other variable names indicating the \"key\" symbol should take its size from the \"value\" symbol\nforce_skip_prep: if true, defer creating internal arrays and other structs until the user calls update_prep!\naviary_input_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of input variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary input variables.\naviary_output_vars::Dict{Symbol,Dict{String,<:Any}}: mapping of output variable names to a Dict that contains keys name and optionally shape defining the Aviary name and shape for Aviary output variables.\naviary_meta_data::Dict{String,Any}: mapping of Aviary variable names to aviary metadata. Currently only the \"units\" and \"default_value\" fields are used.\n\n\n\n\n\n","category":"method"},{"location":"reference/#OpenMDAOCore.VarData","page":"API Reference","title":"OpenMDAOCore.VarData","text":"VarData(name::String; <keyword arguments>)\n\nCreate a VarData object for an OpenMDAO variable named name.\n\nVarData objects are used to construct arguments to OpenMDAO's Component.add_input and Component.add_output methods. Specifically, if a VarData object var refers to an input variable, the Component.add_input call will look like this:\n\nComponent.add_input(var.name, shape=var.shape, val=var.val, units=var.units, tags=var.tags, shape_by_conn=var.shape_by_conn)\n\nand if the VarData object var is an output variable, the Component.add_output call will look like this:\n\nComponent.add_output(var.name, shape=var.shape, val=var.val, units=var.units, lower=var.lower, upper=var.upper, tags=var.tags, shape_by_conn=var.shape_by_conn)\n\nThe name positional argument is required and sets the name field. The value of the other VarData fields (e.g., var.shape, var.val, etc.) are set via constructor keyword arguments, here:\n\nKeyword Arguments\n\nval::Union{Float64,<:AbstractArray{Float64},Nothing} = 1.0: variable's default value, set to 1.0 if nothing.\nshape::Union{Int64,NTuple{N,Int64},Nothing} = (1,): variable shape, set to (1,) if nothing.\nunits::Union{String,Nothing} = nothing: variable units.\nlower::Union{Float64,<:AbstractArray{Float64,N},Nothing} = nothing: variable's lower limit.\nupper::Union{Float64,<:AbstractArray{Float64,N},Nothing} = nothing: variable's upper limit.\ntags::Union{<:AbstractVector{String},Nothing} = nothing: variable tags.\nshape_by_conn::Bool = false: if true, shape this variable by its connected output (if an input) or input (if an output)\ncopy_shape::Union{String,Nothing} = nothing: if a string, shape this variable by the local variable indicated by copy_shape\n\n\n\n\n\n","category":"type"},{"location":"reference/#OpenMDAOCore.get_rows_cols-Tuple{}","page":"API Reference","title":"OpenMDAOCore.get_rows_cols","text":"get_rows_cols(; ss_sizes::Dict{Symbol, Int}, of_ss::AbstractVector{Symbol}, wrt_ss::AbstractVector{Symbol})\n\nGet the non-zero row and column indices for a sparsity pattern defined by output subscripts of_ss and input subscripts wrt_ss.\n\nss_sizes is a Dict mapping the subscript symbols in of_ss and wrt_ss to the size of each dimension the subscript symbols correspond to. The returned indices will be zero-based, which is what the OpenMDAO declare_partials method expects.\n\nExamples\n\nDiagonal partials for 1D output and 1D input, both with length 5:\n\njulia> rows, cols = get_rows_cols(; ss_sizes=Dict(:i=>5), of_ss=[:i], wrt_ss=[:i])\n([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n\n1D output with length 2 depending on all elements of 1D input with length 3 (so not actually sparse).\n\njulia> rows, cols = get_rows_cols(; ss_sizes=Dict(:i=>2, :j=>3), of_ss=[:i], wrt_ss=[:j])\n([0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2])\n\n2D output with size (2, 3) and 1D input with size 2, where each i output row only depends on the i input element.\n\njulia> rows, cols = get_rows_cols(; ss_sizes=Dict(:i=>2, :j=>3), of_ss=[:i, :j], wrt_ss=[:i])\n([0, 1, 2, 3, 4, 5], [0, 0, 0, 1, 1, 1])\n\n2D output with size (2, 3) and 1D input with size 3, where each j output column only depends on the j input element.\n\njulia> rows, cols = get_rows_cols(; ss_sizes=Dict(:i=>2, :j=>3), of_ss=[:i, :j], wrt_ss=[:j])\n([0, 1, 2, 3, 4, 5], [0, 1, 2, 0, 1, 2])\n\n2D output with size (2, 3) depending on input with size (3, 2), where the output element at index i, j only depends on input element j, i (like a transpose operation).\n\njulia> rows, cols = get_rows_cols(; ss_sizes=Dict(:i=>2, :j=>3), of_ss=[:i, :j], wrt_ss=[:j, :i])\n([0, 1, 2, 3, 4, 5], [0, 2, 4, 1, 3, 5])\n\n2D output with size (2, 3) depending on input with size (3, 4), where output y[:, j] for each j depends on input x[j, :].\n\njulia> rows, cols = get_rows_cols(; ss_sizes=Dict(:i=>2, :j=>3, :k=>4), of_ss=[:i, :j], wrt_ss=[:j, :k]);\n\njulia> @show rows cols;  # to prevent abbreviating the array display\nrows = [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5]\ncols = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#OpenMDAOCore.get_rows_cols_dict_from_sparsity-Tuple{ComponentArrays.ComponentMatrix}","page":"API Reference","title":"OpenMDAOCore.get_rows_cols_dict_from_sparsity","text":"get_rows_cols_dict_from_sparsity(J::ComponentMatrix)\n\nGet a Dict of the non-zero row and column indices for a sparsity pattern defined by a ComponentMatrix representation of a Jacobian.\n\n\n\n\n\n","category":"method"},{"location":"reference/#OpenMDAO.make_component","page":"API Reference","title":"OpenMDAO.make_component","text":"make_component(comp::OpenMDAOCore.AbstractComp)\n\nConvinience method for creating either a JuliaExplicitComp or JuliaImplicitComp, depending on if comp is <:OpenMDAOCore.AbstractExplicitComp or <:OpenMDAOCore.AbstractImplicitComp, respectively.\n\n\n\n\n\n","category":"function"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"auto_sparse_ad/#Automatic-Sparse-AD","page":"Auto-Sparse Examples","title":"Automatic Sparse AD","text":"","category":"section"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"OpenMDAOCore.jl can create explicit components that are differentiated automatically by the AD packages supported by DifferentiationInterface.jl, with the derivative calculation accelerated by sparse matrix coloring algorithms. The sparsity pattern can be specified by the user or generated by one of the detection algorithms supported by DifferentiationInterface.jl and dependent packages. The sparsity pattern of the component will also be communicated to OpenMDAO via the rows and cols arguments to add_input and add_output.","category":"page"},{"location":"auto_sparse_ad/#The-User-Defined-Function","page":"Auto-Sparse Examples","title":"The User-Defined Function","text":"","category":"section"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The interface for the automatic sparse forward-mode AD functionality is a bit different from the \"plain\" AbstractExplicitComp and AbstractImplicitComp structs described in earlier examples (see A Simple Example: Optimizing a Paraboloid or A More Complicated Example: Nonlinear Circuit). Instead of creating subtypes of AbstractExplicitComp that implement OpenMDAOCore.setup, OpenMDAOCore.compute!, etc., we'll be writing a Julia function that performs our desired computation. This user-defined function will then be passed to a constructor of the SparseADExplicitComp struct, which will implement the necessary OpenMDAOCore methods for us.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The user-defined function must follow one of two forms: either it can be an \"in-place\" function that writes its outputs to an output vector, or it can be an \"out-of-place\" function that returns a single output vector. Both types must also have a params argument that will contain inputs that are needed for the calculation, but won't be differentiated. So, an example of an in-place function would be ","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function f_in_place!(Y, X, params)\n   # calculate stuff with X and params, storing result in Y\n   return nothing\nend","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"where X is the input vector and Y is the output vector. (The function doesn't have to return nothing, but any returned value will be ignored, so I like to include return nothing to make it clear that the return value doesn't matter.) An out-of-place function would look like","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function f_out_of_place(X, params)\n   # calculate stuff with X and params, returning Y\n   return Y\nend","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"where again X is the input vector.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now, the X and Y arguments of those functions must not be plain Julia Vectors, but ComponentVectors from the ComponentArrays.jl package. What are those? They are objects provided by the ComponentArrays.jl package that act like Vectors, but allow the user to define names for each part (\"component\") of the vector. For example:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"using ComponentArrays: ComponentVector\n\nx1 = ComponentVector(foo=-1.0, bar=-2.0, baz=-3.0)\n@show x1 x1[3] x1.foo x1[:foo]\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Notice that we can get, say, the third value of x1 the usual way (x1[3]), but also by referring to the foo field value via x1.foo and by indexing the ComponentVector with the symbol :foo (x1[:foo]).","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Each of the components in x1 are scalars, but they don't have to be:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"x2 = ComponentVector(foo=-1.0, bar=1:4, baz=reshape(5:10, 2, 3))\n@show x2 x2[:foo] x2[:bar] x2[:baz]\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"In x2, the foo component is a scalar, bar refers to a Vector (aka a 1D Array) and baz refers to a Matrix (aka a 2D Array). But x2 still \"looks like\" a Vector:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"@show x2[3]  # will give the third value of `x2`, which happens to be the second value of x2[:bar]\n@show ndims(x2)  # Should be 1, since a Vector is 1-dimensional\n@show length(x2)  # length(x2) gives the total number of entries in `x2`, aka 1 + 4 + 2*3 = 11\n@show size(x2)  # size is a length-1 tuple since a Vector has just one dimension\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now, how will we use ComponentVectors here? We'll use them to define the names and sizes of all the inputs and outputs to our component. For example, with the paraboloid component in A Simple Example: Optimizing a Paraboloid, we created one component with two inputs x and y and one output f_xy, all scalars. So for that case, our X_ca would be","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"X_ca = ComponentVector(x=1.0, y=1.0)\nY_ca = ComponentVector(f_xy=0.0)\n@show X_ca Y_ca\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Actually, why don't we try to implement the Paraboloid component using a SparseADExplicitComp?","category":"page"},{"location":"auto_sparse_ad/#SparseADExplicitComp-Paraboloid","page":"Auto-Sparse Examples","title":"SparseADExplicitComp Paraboloid","text":"","category":"section"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"We'll start fresh, first with importing the stuff we'll need:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"using ADTypes: ADTypes\nusing ComponentArrays: ComponentVector\nusing OpenMDAOCore: OpenMDAOCore\nusing OpenMDAO: make_component\nusing SparseMatrixColorings: SparseMatrixColorings","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Next, we need to define the function that implements our paraboloid equation, which, again, is","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"f(xy) = (x - 30)^2 + xy + (y + 40)^2 - 30","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"That would look like this:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function f_paraboloid!(Y_ca, X_ca, params)\n    # Get the inputs:\n    x = @view(X_ca[:x])\n    y = @view(X_ca[:y])\n    # Could also do this:\n    # x = X_ca.x\n    # y = X_ca.y\n    # or even this\n    # (; x, y) = X_ca\n\n    # Get the output:\n    f_xy = @view(Y_ca[:f_xy])\n    # Again, could also do this:\n    # f_xy = Y_ca.f_xy\n    # or\n    # (; f_xy) = Y_ca\n\n    # Do the calculation:\n    @. f_xy = (x - 3.0)^2 + x*y + (y + 4.0)^2 - 3.0\n\n    # Return value doesn't matter.\n    return nothing\nend\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"A couple of things to note there:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The @view macro is used when extracting the inputs and outputs from the X_ca and Y_ca ComponentVectors. This creates a view into the original ComponentVector, instead of a new array with a copy of the original data, which avoids unnecessary allocations and (for the outputs) allows modifications to the view to be reflected in the Y_ca array. In this example everything is a scalar, so no allocations would have happened anyway. But it doesn't hurt to use @view: it's a good habit to get into, and it allows us to use the @. broadcasting macro with the scalar f_xy output.\nThe params argument is not used in this example, but it is still required, since the SparseADExplicitComp constructor will expect the function to accept it.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Our next step is to create the ComponentVectors that will be used to hold the inputs and outputs:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"X_ca = ComponentVector(x=1.0, y=1.0)\nY_ca = ComponentVector(f_xy=0.0)\n@show X_ca Y_ca\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"warning: Use sane values for `X_ca`\nThe values of the entries in X_ca will be perturbed slightly when detecting the sparsity pattern of the component's Jacobian, so don't use nonsense values or NaN!","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now we're almost ready to create the SparseADExplicitComp. The last step is to decide what AD library to use. OpenMDAOCore.jl relies on the ADTypes.jl and DifferentiationInterface.jl packages for implementing the interface for calling the AD. Theoretically we can use any AD that those packages support. We'll use ForwardDiff.jl for this example, which is a popular and very robust forward-mode AD.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"using ForwardDiff: ForwardDiff\nsparse_atol = 1e-10\nsparsity_detector = OpenMDAOCore.PerturbedDenseSparsityDetector(ADTypes.AutoForwardDiff(); atol=sparse_atol, method=:direct)\ncoloring_algorithm = SparseMatrixColorings.GreedyColoringAlgorithm()\nad_backend = ADTypes.AutoSparse(ADTypes.AutoForwardDiff(); sparsity_detector=sparsity_detector, coloring_algorithm=coloring_algorithm)\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"That says that we'll use ForwardDiff.jl to both detect the Jacobian sparsity and perform the derivative calculation itself, with a tolerance of 1e-10 for detecting zero entries in the Jacobian. The PerturbedDenseSparsityDetector evaluates the Jacobian multiple times, perturbing the input vector by a small amount, to guard against \"unluckily\" detecting a zero entry in the Jacobian that just happens to be zero for a particular input.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now we are finally ready to create the component:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"comp = OpenMDAOCore.SparseADExplicitComp(ad_backend, f_paraboloid!, Y_ca, X_ca; params=nothing)\nparab_comp = make_component(comp)\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"make_component will convert the SparseADExplicitComp into a OpenMDAO Python component that we can use with OpenMDAO. So now we just need to proceed with the paraboloid example as usual:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"using OpenMDAO: om\n\nmodel = om.Group()\nmodel.add_subsystem(\"parab_comp\", parab_comp)\n\nprob = om.Problem(model)\n\nprob.driver = om.ScipyOptimizeDriver()\nprob.driver.options[\"optimizer\"] = \"SLSQP\"\n\nprob.model.add_design_var(\"parab_comp.x\")\nprob.model.add_design_var(\"parab_comp.y\")\nprob.model.add_objective(\"parab_comp.f_xy\")\n\nprob.setup(force_alloc_complex=true)\n\nprob.set_val(\"parab_comp.x\", 3.0)\nprob.set_val(\"parab_comp.y\", -4.0)\n\nprob.run_model()\nprintln(prob[\"parab_comp.f_xy\"])  # Should print `[-15.]`\n\nprob.set_val(\"parab_comp.x\", 5.0)\nprob.set_val(\"parab_comp.y\", -2.0)\n\nprob.run_model()\nprintln(prob.get_val(\"parab_comp.f_xy\"))  # Should print `[-5.]`\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Looks OK so far. But we should check our derivatives, just to be safe. We can do that with the finite difference method:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"println(prob.check_partials(method=\"fd\"))\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"or the complex-step method:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"println(prob.check_partials(method=\"cs\"))\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Derivatives look great, so let's go ahead and perform the optimization:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"prob.run_driver()\nprintln(\"f_xy = $(prob.get_val(\"parab_comp.f_xy\"))\")  # Should print `[-27.33333333]`\nprintln(\"x = $(prob.get_val(\"parab_comp.x\"))\")  # Should print `[6.66666633]`\nprintln(\"y = $(prob.get_val(\"parab_comp.y\"))\")  # Should print `[-7.33333367]`\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Victory!","category":"page"},{"location":"auto_sparse_ad/#SparseADExplicitComp-with-Actual-Sparsity","page":"Auto-Sparse Examples","title":"SparseADExplicitComp with Actual Sparsity","text":"","category":"section"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The Paraboloid example does a nice job of showing how to use SparseADExplicitComp, but careful readers will realize that it's not actually sparse! So let's try an example with some sparse components: the Simple Optimization using Simultaneous Derivatives example from the OpenMDAO docs. That example makes heavy use of ExecComps with has_diag_partials, but we'll use SparseADExplicitComp to implement each component, and allow it to find the sparsity pattern for us.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Let's start with a fresh Julia script and load what we'll need:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"using ADTypes: ADTypes\nusing ComponentArrays: ComponentVector\nusing OpenMDAOCore: OpenMDAOCore\nusing OpenMDAO: make_component, om\nusing SparseMatrixColorings: SparseMatrixColorings\n\n# Use the same value of `SIZE` that the official version uses:\nSIZE = 10\n\n# Use the same AD as the previous example: ForwardDiff.jl, with `PerturbedDenseSparsityDetector`.\nsparse_atol = 1e-10\nsparsity_detector = OpenMDAOCore.PerturbedDenseSparsityDetector(ADTypes.AutoForwardDiff(); atol=sparse_atol, method=:direct)\ncoloring_algorithm = SparseMatrixColorings.GreedyColoringAlgorithm()\nad_backend = ADTypes.AutoSparse(ADTypes.AutoForwardDiff(); sparsity_detector=sparsity_detector, coloring_algorithm=coloring_algorithm)","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now we'll need to create some functions that will implement the various calculations we need. Here are the functions for arctan_yox, circle, and r_con, respectively:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function f_arctan_yox!(Y, X, params)\n    # Get views of inputs.\n    x = @view(X[:x])\n    y = @view(X[:y])\n\n    # Get views of outputs.\n    g = @view(Y[:g])\n\n    # Perform the calculation.\n    @. g = atan(y/x)\n\n    return nothing\nend\nY_ca = ComponentVector(g=ones(SIZE))\nX_ca = ComponentVector(x=ones(SIZE), y=ones(SIZE))\ncomp = OpenMDAOCore.SparseADExplicitComp(ad_backend, f_arctan_yox!, Y_ca, X_ca)\narctan_yox_comp = make_component(comp)\n\nfunction f_circle!(Y, X, params)\n    # Get views of inputs.\n    r = X.r\n\n    # Get views of outputs.\n    # area = Y.area\n    area = @view(Y[:area])\n\n    # Perform the calculation.\n    @. area = pi*r^2\n\n    return nothing\nend\nY_ca = ComponentVector(area=1.0)\nX_ca = ComponentVector(r=1.0)\ncomp = OpenMDAOCore.SparseADExplicitComp(ad_backend, f_circle!, Y_ca, X_ca)\ncircle_comp = make_component(comp)\n\nfunction f_r_con!(Y, X, params)\n    # Get views of inputs.\n    (; x, y, r) = X\n\n    # Get views of outputs.\n    g = Y.g\n\n    # Perform the calculation.\n    @. g = x^2 + y^2 - r\n\n    return nothing\nend\nY_ca = ComponentVector(g=ones(SIZE))\nX_ca = ComponentVector(x=ones(SIZE), y=ones(SIZE), r=1.0)\ncomp = OpenMDAOCore.SparseADExplicitComp(ad_backend, f_r_con!, Y_ca, X_ca)\nr_con_comp = make_component(comp)\n\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"We can check that SparseADExplicitComp has detected the diagonal partials by getting the rows and columns Dict that it constructs. For that last component:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"rcdict = OpenMDAOCore.get_rows_cols_dict(comp)\n@show rcdict[:g, :x] rcdict[:g, :y] rcdict[:g, :r]\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The rcdict maps the partials to a tuple of two vectors containing the non-zero rows and non-zero columns of the partial. For example, that output above shows that the derivative of ","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"g[1] with respect to x[1]\ng[2] with respect to x[2]\ng[3] with respect to x[3]","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"etc are all non-zero, and similar for the derivatives of g with respect to y. All entries of g depend on the single value of r, and so rcdict[:g, :r] shows that all indices of g (1 through 10) depend on the single 1 index of r.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Next, let's think about the calculation for the theta_con component, which in the Python example looks like this:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"thetas = np.linspace(0, np.pi/4, SIZE)\np.model.add_subsystem('theta_con', om.ExecComp('g = x - theta', has_diag_partials=True,\n                                               g=np.ones(SIZE), x=np.ones(SIZE),\n                                               theta=thetas))","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The theta array is hard-coded to go from 0 to pi/4, but what if we wanted to be able to change that? We could use the params argument to the user-defined function to set the starting and ending value for theta, like so:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function f_theta_con!(Y, X, params)\n    # Get views of inputs.\n    x = @view(X[:x])\n\n    # Get views of outputs.\n    g = @view(Y[:g])\n\n    # Create the theta parameter.\n    theta_min = params.theta_min\n    theta_max = params.theta_max\n    theta = range(theta_min, theta_max; length=length(x))\n\n    # Perform the calculation.\n    @. g = x - theta\n\n    return nothing\nend\n\nY_ca = ComponentVector(g=ones(SIZE))\nX_ca = ComponentVector(x=ones(SIZE))\nparams_theta_con = (theta_min=0.0, theta_max=pi/4)\ncomp = OpenMDAOCore.SparseADExplicitComp(ad_backend, f_theta_con!, Y_ca, X_ca; params=params_theta_con)\ntheta_con_comp = make_component(comp)\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Notice that we decided to use a NamedTuple for the params argument. It could be anything, as long as it's consistent with the definition of f_theta_con!. For example, we could have passed a Vector [0.0, pi/4] to SparseADExplicitComp, then done something like","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"theta_min = params[1]\ntheta_max = params[2]","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"in the definition of f_theta_con!. But then we would have had to remember that theta_min is the first entry in params, theta_max the second. Much easier to use a NamedTuple.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Finally, let's create the functions for the delta_theta_con and l_conx components:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function f_delta_theta_con!(Y, X, params)\n    # Get views of inputs.\n    # even = @view(X[:even])\n    # odd = @view(X[:odd])\n    (; even, odd) = X\n\n    # Get views of outputs.\n    # g = @view(Y[:g])\n    (; g) = Y\n\n    # Perform the calculation.\n    @. g = even - odd\n\n    return nothing\nend\nY_ca = ComponentVector(g=ones(SIZE÷2))\nX_ca = ComponentVector(even=ones(SIZE÷2), odd=ones(SIZE÷2))\ncomp = OpenMDAOCore.SparseADExplicitComp(ad_backend, f_delta_theta_con!, Y_ca, X_ca)\ndelta_theta_con_comp = make_component(comp)\n\nfunction f_l_conx!(Y, X, params)\n    # Get views of inputs.\n    x = @view(X[:x])\n\n    # Get views of outputs.\n    g = @view(Y[:g])\n\n    # Perform the calculation.\n    @. g = x - 1\n\n    return nothing\nend\nY_ca = ComponentVector(g=ones(SIZE))\nX_ca = ComponentVector(x=ones(SIZE))\ncomp = OpenMDAOCore.SparseADExplicitComp(ad_backend, f_l_conx!, Y_ca, X_ca)\nl_conx_comp = make_component(comp)\n\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Excellent. Now we're finally ready to start creating the OpenMDAO Problem. The rest of the example will closely follow the official version.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"\np = om.Problem()\n\np.model.add_subsystem(\"arctan_yox\", arctan_yox_comp, promotes_inputs=[\"x\", \"y\"])\np.model.add_subsystem(\"circle\", circle_comp, promotes_inputs=[\"r\"])\np.model.add_subsystem(\"r_con\", r_con_comp, promotes_inputs=[\"r\", \"x\", \"y\"])\np.model.add_subsystem(\"theta_con\", theta_con_comp)\np.model.add_subsystem(\"delta_theta_con\", delta_theta_con_comp)\np.model.add_subsystem(\"l_conx\", l_conx_comp, promotes_inputs=[\"x\"])\n\n# OpenMDAO uses 0-based indices, so need to go from 0 to SIZE-1.\nIND = 0:SIZE-1\n# Julia arrays are 1-based, so 1 will give us the first index, 2 the second, etc..\n# Could also use the popular OffsetArrays.jl package to create a 0-based array.\nODD_IND = IND[2:2:end]  # all odd indicies\nEVEN_IND = IND[1:2:end-1]  # all even indices\n\np.model.connect(\"arctan_yox.g\", \"theta_con.x\")\np.model.connect(\"arctan_yox.g\", \"delta_theta_con.even\", src_indices=EVEN_IND)\np.model.connect(\"arctan_yox.g\", \"delta_theta_con.odd\", src_indices=ODD_IND)\n\np.driver = om.ScipyOptimizeDriver()\np.driver.options[\"optimizer\"] = \"SLSQP\"\np.driver.options[\"disp\"] = false\n\n# set up dynamic total coloring here\np.driver.declare_coloring()\n\np.model.add_design_var(\"x\")\np.model.add_design_var(\"y\")\np.model.add_design_var(\"r\", lower=.5, upper=10)\n\n# nonlinear constraints\np.model.add_constraint(\"r_con.g\", equals=0)\n\np.model.add_constraint(\"theta_con.g\", lower=-1e-5, upper=1e-5, indices=EVEN_IND)\np.model.add_constraint(\"delta_theta_con.g\", lower=-1e-5, upper=1e-5)\n\n# this constrains x[0] to be 1 (see definition of l_conx)\np.model.add_constraint(\"l_conx.g\", equals=0, linear=false, indices=[0,])\n\n# linear constraint\np.model.add_constraint(\"y\", equals=0, indices=[0,], linear=true)\n\np.model.add_objective(\"circle.area\", ref=-1)\n\np.setup(mode=\"fwd\", force_alloc_complex=true)\n\n# the following were randomly generated using np.random.random(10)*2-1 to randomly\n# disperse them within a unit circle centered at the origin.\np.set_val(\"x\", [ 0.55994437, -0.95923447,  0.21798656, -0.02158783,  0.62183717,\n                 0.04007379,  0.46044942, -0.10129622,  0.27720413, -0.37107886])\np.set_val(\"y\", [ 0.52577864,  0.30894559,  0.8420792 ,  0.35039912, -0.67290778,\n                -0.86236787, -0.97500023,  0.47739414,  0.51174103,  0.10052582])\np.set_val(\"r\", .7)\n\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Let's check our derivatives:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"println(p.check_partials(method=\"cs\"))\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Essentially zero error in the derivatives, so that's great.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Finally, let's do the optimization:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"p.run_driver()\nprintln(\"circle.area = $(p[\"circle.area\"]) (should be about equal to π ≈ $(float(pi)))\")\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"We got the right answer! Yay!","category":"page"},{"location":"auto_sparse_ad/#The-Brachistochrone-with-SparseADExplicitComp","page":"Auto-Sparse Examples","title":"The Brachistochrone with SparseADExplicitComp","text":"","category":"section"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Finally, let's implement the Brachistochrone problem from A Simple Dymos Example using SparseADExplicitComp. This will demonstrate how to add units and tags to variables used in a SparseADExplicitComp component.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"First, let's start a new Julia script, and import Dymos:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"using ADTypes: ADTypes\nusing ComponentArrays: ComponentVector\nusing OpenMDAOCore: OpenMDAOCore\nusing OpenMDAO: om, make_component\nusing PythonCall: pyimport, pydict\nusing SparseMatrixColorings: SparseMatrixColorings\n\ndm = pyimport(\"dymos\")\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Next, let's define the Brachistochrone ODE that takes in ComponentVectors.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function brachistochrone_ode!(Y, X, params)\n    theta = @view X[:theta]\n    g = X.g\n    v = X.v\n\n    cos_theta = cos.(theta)\n    sin_theta = sin.(theta)\n\n    # @view(Y[:vdot]) .= g .* cos_theta\n    # @view(Y[:xdot]) .= v .* sin_theta\n    # @view(Y[:ydot]) .= -v .* cos_theta\n    # @view(Y[:check]) .= v ./ sin_theta\n    (; vdot, xdot, ydot, check) = Y\n    vdot .= g .* cos_theta\n    xdot .= v .* sin_theta\n    ydot .= -v .* cos_theta\n    check .= v ./ sin_theta\n\n    return nothing\nend\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now, for the tricky part: we need to give Dymos a function that, when passed the num_nodes keyword argument, returns a component that implements the ODE. The component this yet-to-be-written function will return will be a SparseADExplicitComp, and that means we will need to also create the required ComponentVectors for the inputs and outputs. How will we do that? Like this:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function brachistochrone_ode_factory(; num_nodes, static_gravity)\n    v = rand(Float64, num_nodes) .+ 1\n    theta = rand(Float64, num_nodes) .+ 2\n    if static_gravity\n        g = 9.81\n    else\n        g = fill(9.81, num_nodes)\n    end\n    X_ca = ComponentVector(v=v, theta=theta, g=g)\n\n    xdot = zeros(num_nodes)\n    ydot = zeros(num_nodes)\n    vdot = zeros(num_nodes)\n    check = zeros(num_nodes)\n    Y_ca = ComponentVector(xdot=xdot, ydot=ydot, vdot=vdot, check=check)\n\n    units_dict = Dict(:v=>\"m/s\", :theta=>\"rad\", :g=>\"m/s**2\", :xdot=>\"m/s\", :ydot=>\"m/s\", :vdot=>\"m/s**2\", :check=>\"m/s\")\n    tags_dict = Dict(\n        :xdot=>[\"dymos.state_rate_source:x\", \"dymos.state_units:m\"],\n        :ydot=>[\"dymos.state_rate_source:y\", \"dymos.state_units:m\"],\n        :vdot=>[\"dymos.state_rate_source:v\", \"dymos.state_units:m/s\"],\n    )\n    if static_gravity\n        tags_dict[:g] = [\"dymos.static_target\"]\n    end\n\n    # Use the same AD as the previous example: ForwardDiff.jl, with `PerturbedDenseSparsityDetector`.\n    sparse_atol = 1e-10\n    sparsity_detector = OpenMDAOCore.PerturbedDenseSparsityDetector(ADTypes.AutoForwardDiff(); atol=sparse_atol, method=:direct)\n    coloring_algorithm = SparseMatrixColorings.GreedyColoringAlgorithm()\n    ad_backend = ADTypes.AutoSparse(ADTypes.AutoForwardDiff(); sparsity_detector=sparsity_detector, coloring_algorithm=coloring_algorithm)\n\n    return make_component(OpenMDAOCore.SparseADExplicitComp(ad_backend, brachistochrone_ode!, Y_ca, X_ca; units_dict=units_dict, tags_dict=tags_dict))\nend\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"brachistochrone_ode_factory takes to keyword arguments: the num_nodes argument that Dymos requires, and the static_gravity argument from the original Dymos example. Once we know the value of num_nodes, we can create the X_ca and Y_ca ComponentVectors as usual, with the static_gravity parameter influencing the size of g. We also create two dictionaries: units_dict and tags_dict. units_dict maps variable names (expressed as Symbols, just like the component names for the ComponentVectors) to Strings defining the units of the variable. The tags_dict similarly maps Symbol variable names to Vectors of String specifying the tags for each variable. Both Dicts are passed to the SparseADExplicitComp constructor as keyword arguments. Finally, the resulting SparseADExplicitComp is passed to make_component to actually create the Python OpenMDAO component.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now, let's actually define the problem and run the optimization. We'll define a driver function called doit that allows us to try the example with the static_gravity argument set to true and false.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function doit(; static_gravity)\n    # Initialize the Problem and the optimization driver\n    #\n    p = om.Problem(model=om.Group())\n    p.driver = om.ScipyOptimizeDriver()\n    p.driver.declare_coloring()\n    #\n    # Create a trajectory and add a phase to it\n    #\n    traj = p.model.add_subsystem(\"traj\", dm.Trajectory())\n           \n\n    phase = traj.add_phase(\"phase0\",\n                           dm.Phase(ode_class=brachistochrone_ode_factory, ode_init_kwargs=pydict(Dict(\"static_gravity\"=>static_gravity)),\n                                    transcription = dm.GaussLobatto(num_segments=10)))\n\n    #\n    # Set the variables\n    #\n    phase.set_time_options(fix_initial=true, duration_bounds=(.5, 10))\n\n    phase.add_state(\"x\", fix_initial=true, fix_final=true)\n\n    phase.add_state(\"y\", fix_initial=true, fix_final=true)\n\n    phase.add_state(\"v\", fix_initial=true, fix_final=false)\n\n    phase.add_control(\"theta\", continuity=true, rate_continuity=true,\n                      units=\"deg\", lower=0.01, upper=179.9)\n\n    phase.add_parameter(\"g\", units=\"m/s**2\", val=9.80665)\n\n    #\n    # Minimize time at the end of the phase\n    #\n    phase.add_objective(\"time\", loc=\"final\", scaler=10)\n    # \n    p.model.linear_solver = om.DirectSolver()\n    #\n    # Setup the Problem\n    #\n    p.setup()\n\n    #\n    # Set the initial values\n    #\n    p[\"traj.phase0.t_initial\"] = 0.0\n    p[\"traj.phase0.t_duration\"] = 2.0\n\n    p.set_val(\"traj.phase0.states:x\", phase.interp(\"x\", ys=[0, 10]))\n    p.set_val(\"traj.phase0.states:y\", phase.interp(\"y\", ys=[10, 5]))\n    p.set_val(\"traj.phase0.states:v\", phase.interp(\"v\", ys=[0, 9.9]))\n    p.set_val(\"traj.phase0.controls:theta\", phase.interp(\"theta\", ys=[5, 100.5]))\n\n    #\n    # Solve for the optimal trajectory\n    #\n    dm.run_problem(p)\n\n    # Check the results\n    println(\"static_gravity = $static_gravity, elapsed time = $(p.get_val(\"traj.phase0.timeseries.time\")[-1]) (should be 1.80164719)\")\nend\n\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The doit function is essentially identical to the previous version from A Simple Dymos Example. The only difference is in the ode_class argument in the call to dm.Phase: we assign that argument to our brachistochrone_ode_factory function. We also need to tell Dymos about the value of the static_gravity option we would like to use, which can be done via the ode_init_kwargs argument. In Python, this would normally be a dict with string keys. To do this in Julia, we first create a Dict with String keys, then use the pydict function from PythonCall to convert the Julia Dict to a Python dict.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"With all that in place, we can run the optimization! Let's try with static_gravity=true:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"doit(; static_gravity=true)\n\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Got the right answer!","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"And now, static_gravity=false:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"doit(; static_gravity=false)\n\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Also looks good!","category":"page"},{"location":"auto_sparse_ad/#The-Brachistochrone-with-SparseADExplicitComp-and-User-Defined-Sparsity","page":"Auto-Sparse Examples","title":"The Brachistochrone with SparseADExplicitComp and User-Defined Sparsity","text":"","category":"section"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Having OpenMDAOCore.jl determine the sparsity pattern of your component is quite convent, but involves evaluating the full Jacobian multiple times, which may be expensive depending on the complexity of your component. Often it's quite easy to figure out the sparsity pattern yourself, and DifferentiationInterface.jl supports a user-defined sparsity pattern. So let's learn how to do that with the previous Brachistochrone example.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"We'll start fresh again:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"using ADTypes: ADTypes\nusing ComponentArrays: ComponentVector, ComponentMatrix, getdata, getaxes\nusing OpenMDAOCore: OpenMDAOCore\nusing OpenMDAO: om, make_component\nusing PythonCall: pyimport, pydict\nusing SparseArrays: sparse\nusing SparseMatrixColorings: SparseMatrixColorings\n\ndm = pyimport(\"dymos\")\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"We'll implement the same ODE, but this time let's try doing an out-of-place callback function, just for fun:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function brachistochrone_ode(X, params)\n    theta = @view X[:theta]\n    g = X.g\n    v = X.v\n\n    cos_theta = cos.(theta)\n    sin_theta = sin.(theta)\n\n    vdot = g .* cos_theta\n    xdot = v .* sin_theta\n    ydot = -v .* cos_theta\n    check = v ./ sin_theta\n\n    return ComponentVector(vdot=vdot, xdot=xdot, ydot=ydot, check=check)\nend\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"We also need a \"factory function\" like last time that will take num_nodes as a keyword argument, and define units and takes, and finally returns an OpenMDAO Python component. Now, to use user-defined sparsity, we need to be able to create a sparse matrix representing the Jacobian of our component, with zeros for all the zero entries, of course. The easiest way to do that is to create a ComponentMatrix inside the factory function, like so:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"function brachistochrone_ode_factory(; num_nodes, static_gravity)\n    v = rand(Float64, num_nodes) .+ 1\n    theta = rand(Float64, num_nodes) .+ 2\n    if static_gravity\n        g = 9.81\n    else\n        g = fill(9.81, num_nodes)\n    end\n    X_ca = ComponentVector(v=v, theta=theta, g=g)\n\n    # Get the output ComponentVector by calling the ODE function.\n    Y_ca = brachistochrone_ode(X_ca, nothing)\n\n    # Create a Matrix representing the Jacobian, with the number of rows equal to the number of outputs, and the number of columns equal to the number of inputs:\n    J = zeros(length(Y_ca), length(X_ca))\n    # Now create a ComponentMatrix from J, with the appropriate names for the inputs and outputs:\n    J_ca = ComponentMatrix(J, only(getaxes(Y_ca)), only(getaxes(X_ca)))\n    # Fill the ComponentMatrix with zeros first...\n    J_ca .= 0.0\n\n    # Now mark all the non-zero entries with 1.0.\n    for n in 1:num_nodes\n        # vdot are functions of theta and g.\n        @view(J_ca[:vdot, :theta])[n, n] = 1.0\n        if static_gravity\n            @view(J_ca[:vdot, :g])[n, 1] = 1.0\n        else\n            @view(J_ca[:vdot, :g])[n, n] = 1.0\n        end\n\n        # xdot, ydot, and check depend on v and theta.\n        @view(J_ca[:xdot, :theta])[n, n] = 1.0\n        @view(J_ca[:xdot, :v])[n, n] = 1.0\n        @view(J_ca[:ydot, :theta])[n, n] = 1.0\n        @view(J_ca[:ydot, :v])[n, n] = 1.0\n        @view(J_ca[:check, :theta])[n, n] = 1.0\n        @view(J_ca[:check, :v])[n, n] = 1.0\n    end\n\n    units_dict = Dict(:v=>\"m/s\", :theta=>\"rad\", :g=>\"m/s**2\", :xdot=>\"m/s\", :ydot=>\"m/s\", :vdot=>\"m/s**2\", :check=>\"m/s\")\n    tags_dict = Dict(\n        :xdot=>[\"dymos.state_rate_source:x\", \"dymos.state_units:m\"],\n        :ydot=>[\"dymos.state_rate_source:y\", \"dymos.state_units:m\"],\n        :vdot=>[\"dymos.state_rate_source:v\", \"dymos.state_units:m/s\"],\n    )\n    if static_gravity\n        tags_dict[:g] = [\"dymos.static_target\"]\n    end\n\n    # Use the same AD as the previous example: ForwardDiff.jl, with `PerturbedDenseSparsityDetector`.\n    sparsity_detector = ADTypes.KnownJacobianSparsityDetector(sparse(getdata(J_ca)))\n    coloring_algorithm = SparseMatrixColorings.GreedyColoringAlgorithm()\n    ad_backend = ADTypes.AutoSparse(ADTypes.AutoForwardDiff(); sparsity_detector=sparsity_detector, coloring_algorithm=coloring_algorithm)\n\n    return make_component(OpenMDAOCore.SparseADExplicitComp(ad_backend, brachistochrone_ode, X_ca; units_dict=units_dict, tags_dict=tags_dict))\nend\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Let's break down the portion of the code that creates and sets J_ca. We start by creating some examples of X_ca and Y_ca to play around with:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"nn = 4\nX_ca_test = ComponentVector(v=range(1.0, 2.0; length=nn), theta=range(2.0, 3.0, length=nn), g=9.81)\nY_ca_test = brachistochrone_ode(X_ca_test, nothing)\n@show X_ca_test Y_ca_test\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now we create a Matrix representing the Jacobian, with the number of rows equal to the number of outputs, and the number of columns equal to the number of inputs:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"J_test = zeros(length(Y_ca_test), length(X_ca_test))","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"The size of J_test is (16, 9) which is what we expect: there are 4 + 4 + 1 = 9 inputs and 4 + 4 + 4 + 4=16 outputs. But we want to create a ComponentMatrix so we can easily pull out the sub-Jacobians. The easiest way to do that is to get the \"axes\" for the input and output ComponentVectors, and then use those when constructing the ComponentMatrix like so. To get the axes, we use the getaxes function from ComponentArrays.jl. For the input ComponentVector:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"X_axes = getaxes(X_ca_test)","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"and for the output ComponentVector:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Y_axes = getaxes(Y_ca_test)","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now we create a ComponentMatrix like so:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"J_ca_test = ComponentMatrix(J_test, only(Y_axes), only(X_axes))","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"(only is a small Julia function that returns the single value of a length-1 collection [Array, Tuple, etc.] or throws an error if called on something with more than one value.) Now that we have a ComponentMatrix, it's relatively easy to set the non-zero entries to something other than zero. For example, the, say, second entry of vdot depends on the second entry of theta, and we can communicate that by doing this:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"@view(J_ca_test[:vdot, :theta])[2, 2] = 1.0\nJ_ca_test","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"As explained in the ComponentArrays.jl docs, the @view macro is necessary to modify elements of J_ca_test—otherwise we would be modifying a copy of a portion of J_ca_test, since slicing operations in Julia create copies.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Now, we're ready to start creating an OpenMDAO Problem, like last time:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"# Initialize the Problem and the optimization driver\n#\np = om.Problem(model=om.Group())\np.driver = om.ScipyOptimizeDriver()\np.driver.declare_coloring()\n#\n# Create a trajectory and add a phase to it\n#\ntraj = p.model.add_subsystem(\"traj\", dm.Trajectory())\n       \nstatic_gravity = false\nphase = traj.add_phase(\"phase0\",\n                       dm.Phase(ode_class=brachistochrone_ode_factory, ode_init_kwargs=pydict(Dict(\"static_gravity\"=>static_gravity)),\n                                transcription = dm.GaussLobatto(num_segments=10)))\n\n#\n# Set the variables\n#\nphase.set_time_options(fix_initial=true, duration_bounds=(.5, 10))\n\nphase.add_state(\"x\", fix_initial=true, fix_final=true)\n\nphase.add_state(\"y\", fix_initial=true, fix_final=true)\n\nphase.add_state(\"v\", fix_initial=true, fix_final=false)\n\nphase.add_control(\"theta\", continuity=true, rate_continuity=true,\n                  units=\"deg\", lower=0.01, upper=179.9)\n\nphase.add_parameter(\"g\", units=\"m/s**2\", val=9.80665)\n\n#\n# Minimize time at the end of the phase\n#\nphase.add_objective(\"time\", loc=\"final\", scaler=10)\n# \np.model.linear_solver = om.DirectSolver()\n#\n# Setup the Problem\n#\np.setup(force_alloc_complex=true)\n\n#\n# Set the initial values\n#\np[\"traj.phase0.t_initial\"] = 0.0\np[\"traj.phase0.t_duration\"] = 2.0\n\np.set_val(\"traj.phase0.states:x\", phase.interp(\"x\", ys=[0, 10]))\np.set_val(\"traj.phase0.states:y\", phase.interp(\"y\", ys=[10, 5]))\np.set_val(\"traj.phase0.states:v\", phase.interp(\"v\", ys=[0, 9.9]))\np.set_val(\"traj.phase0.controls:theta\", phase.interp(\"theta\", ys=[5, 100.5]))\n\nnothing # hide","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"But it would be a good idea to check our derivatives first, since that should reveal any bugs in our sparsity pattern.","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"# Not sure why I have to do this song and dance.\nusing PythonCall: PyIO\nfoo = pyimport(\"io\").StringIO()\nbar = PyIO(foo)\np.check_partials(out_stream=bar, method=\"cs\")\nflush(bar)\nfoo.seek(0)\nprintln(foo.read())","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Derivatives look good. So now let's run the optimization:","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"#\n# Solve for the optimal trajectory\n#\ndm.run_problem(p)\n\n# Check the results\nprintln(\"elapsed time = $(p.get_val(\"traj.phase0.timeseries.time\")[-1]) (should be 1.80164719)\")","category":"page"},{"location":"auto_sparse_ad/","page":"Auto-Sparse Examples","title":"Auto-Sparse Examples","text":"Again, looks good!","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"#OpenMDAO.jl-Documentation","page":"Home","title":"OpenMDAO.jl Documentation","text":"","category":"section"},{"location":"#What?","page":"Home","title":"What?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Use Julia with OpenMDAO! OpenMDAO.jl is a Julia package that allows a user to:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Write OpenMDAO Components in Julia, and incorporate these components into a OpenMDAO model.\nCreate and run optimizations in Julia, using OpenMDAO as a library.","category":"page"},{"location":"","page":"Home","title":"Home","text":"OpenMDAO.jl consists of three pieces of software:","category":"page"},{"location":"","page":"Home","title":"Home","text":"OpenMDAOCore.jl: A small, pure-Julia package that allows users to define Julia code that will eventually be used in an OpenMDAO Problem. OpenMDAOCore.jl defines two Julia abstract types (AbstractExplicitComponent and AbstractImplicitComponent) and methods that mimic OpenMDAO's ExplicitComponent and ImplicitComponent classes.\nomjlcomps: A Python package (actually, a OpenMDAO Plugin) that defines two classes, JuliaExplicitComp and JuliaImplicitComp, which inherit from OpenMDAO's ExplicitComponent and ImplicitComponent, respectively. These components take instances of concrete subtypes of OpenMDAOCore.ExplicitComponent and OpenMDAOCore.ImplicitComponent and turn them into instances of JuliaExplicitComp and JuliaImplicitComp. Like any other OpenMDAO ExplicitComponent or ImplicitComponent objects, JuliaExplicitComp and JuliaImplicitComp instances can be used in an OpenMDAO model, but call Julia code in their methods (compute, apply_nonlinear, etc.).\nOpenMDAO.jl: A Julia package that has the openmdao and omjlcomps Python packages as dependencies. Users can install OpenMDAO.jl and have the full power of the OpenMDAO framework at their disposal in Julia.","category":"page"},{"location":"#How-(Installation-Instructions)?","page":"Home","title":"How (Installation Instructions)?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"There are two approaches to getting OpenMDAO working with Julia: the Python-Centric Approach and the Julia-Centric Approach. If you like Python and just want to have a little (or a lot) of Julia buried in your OpenMDAO System, then you'll probably prefer the Python-centric approach. If you're a huge fan of Julia and would like to pretend that OpenMDAO is a Julia library, you'll want the Julia-centric approach. Either way, pick one or the other: you don't need to follow both installation instructions.","category":"page"},{"location":"#python_centric","page":"Home","title":"Python-Centric Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The first (and only!) step is to install omjlcomps, which is in the Python Package Index, so a simple","category":"page"},{"location":"","page":"Home","title":"Home","text":"pip install omjlcomps","category":"page"},{"location":"","page":"Home","title":"Home","text":"should be all you need. omjlcomps uses JuliaPkg to manage Julia dependencies, so all the Julia packages needed by omjlcomps (and even Julia itself, if necessary) will be installed automatically.","category":"page"},{"location":"#julia_centric","page":"Home","title":"Julia-Centric Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The OpenMDAOCore.jl and OpenMDAO.jl Julia packages are registered in the General registry, so installation should be as simple as","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add OpenMDAOCore OpenMDAO","category":"page"},{"location":"","page":"Home","title":"Home","text":"in the Julia REPL. OpenMDAOCore.jl is a fairly small package without any Python dependencies, but OpenMDAO.jl depends on omjlcomps and openmdao itself. OpenMDAO.jl's Python dependencies are managed by CondaPkg, and should be automatically installed into a separate Conda environment specific to your current Julia environment.","category":"page"},{"location":"#Acknowledgements","page":"Home","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"An early version of OpenMDAO.jl was written by Daniel Ingraham, Justin Gray, and Andrew Ning while visiting Prof. Ning at Brigham Young University.\nOpenMDAO.jl depends heavily on PythonCall and related packages, developed by Christopher Rowley.","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"CurrentModule = OpenMDAODocs","category":"page"},{"location":"matrix_free_ad/#(Experimental)-Automatic-Matrix-Free-AD","page":"Auto-Matrix-Free Examples","title":"(Experimental) Automatic Matrix-Free AD","text":"","category":"section"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"OpenMDAOCore.jl can create explicit components that are differentiated automatically by the AD packages supported by DifferentiationInterface.jl using Jacobian-vector or vector-Jacobian products instead of assembling the complete Jacobian. The resulting components will use the OpenMDAO Matrix-Free API.","category":"page"},{"location":"matrix_free_ad/#The-User-Defined-Function","page":"Auto-Matrix-Free Examples","title":"The User-Defined Function","text":"","category":"section"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"The requirements for the user-defined function for the matrix-free AD functionality is identical to those for Automatic Sparse AD, and the interface is much the same, as well. We'll still need to provide a function that expects a ComponentVector for its input, and either write its outputs to a ComponentVector (for the in-place form) or return a ComponentVector with outputs (for the out-of-place form). The only significant difference is that users will create a MatrixFreeADExplicitComp instead of a SparseADExplicitComp.","category":"page"},{"location":"matrix_free_ad/#MatrixFreeADExplicitComp-Paraboloid","page":"Auto-Matrix-Free Examples","title":"MatrixFreeADExplicitComp Paraboloid","text":"","category":"section"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"Let's do the good old Paraboloid example yet again, this time with the MatrixFreeADExplicitComp. We'll load the same packages as we did for the sparse AD example (except we don't need SparseMatrixColorings since we won't be doing sparsity):","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"using ADTypes: ADTypes\nusing ComponentArrays: ComponentVector\nusing OpenMDAOCore: OpenMDAOCore\nusing OpenMDAO: make_component","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"We'll be using the same paraboloid function, but this time let's create an out-of-place function:","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"function f_paraboloid(X_ca, params)\n    # Get the inputs:\n    # Using @view with ReverseDiff.jl doesn't work for some reason.\n    # x = @view(X_ca[:x])\n    # y = @view(X_ca[:y])\n    # Could also do this:\n    x = X_ca.x\n    y = X_ca.y\n    # or even this\n    # (; x, y) = X_ca\n\n    # Do the calculation:\n    f_xy = @. (x - 3.0)^2 + x*y + (y + 4.0)^2 - 3.0\n\n    return ComponentVector(f_xy=f_xy)\nend\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"(For some reason the @view macro doesn't work with ReverseDiff.jl, the AD library we'll use for this example.)","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"Now we'll create the input ComponentVector. No need to create the output ComponentVector for the out-of-place callback function.","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"X_ca = ComponentVector(x=1.0, y=1.0)\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"And finally we'll decide which AD library we'll use. For this one, let's try ReverseDiff.jl:","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"using ReverseDiff: ReverseDiff\nad_backend = ADTypes.AutoReverseDiff()\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"Now we can create the component:","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"comp = OpenMDAOCore.MatrixFreeADExplicitComp(ad_backend, f_paraboloid, X_ca)\nparab_comp = make_component(comp)\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"As before, make_component will convert the MatrixFreeADExplicitComp into a OpenMDAO Python component that we can use with OpenMDAO. So now we just need to proceed with the paraboloid example as usual. But! We need to make sure to tell OpenMDAO that we need to calculate total derivatives in reverse mode, not forward, since we're using reverse AD for our paraboloid component. We do that by supplying the mode=\"rev\" argument to Problem.setup().","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"using OpenMDAO: om\n\nprob = om.Problem()\n\nmodel = om.Group()\nmodel.add_subsystem(\"parab_comp\", parab_comp)\n\nprob = om.Problem(model)\n\nprob.driver = om.ScipyOptimizeDriver()\nprob.driver.options[\"optimizer\"] = \"SLSQP\"\n\nprob.model.add_design_var(\"parab_comp.x\")\nprob.model.add_design_var(\"parab_comp.y\")\nprob.model.add_objective(\"parab_comp.f_xy\")\n\nprob.setup(force_alloc_complex=true, mode=\"rev\")\n\nprob.set_val(\"parab_comp.x\", 3.0)\nprob.set_val(\"parab_comp.y\", -4.0)\n\nprob.run_model()\nprintln(prob[\"parab_comp.f_xy\"])  # Should print `[-15.]`\n\nprob.set_val(\"parab_comp.x\", 5.0)\nprob.set_val(\"parab_comp.y\", -2.0)\n\nprob.run_model()\nprintln(prob.get_val(\"parab_comp.f_xy\"))  # Should print `[-5.]`\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"Looks good. Let's check our derivatives using finite difference:","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"println(prob.check_partials(method=\"fd\"))\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"Now, some of the derivatives don't look so great! Why? There's a hint at the beginning of the output above in the form of a warning from OpenMDAOCore.jl. When checking the partial derivatives of a matrix-free component, OpenMDAO runs the component in both forward and reverse mode, showing the results in the output above as Jfor for forward, Jrev for reverse (and Jfd for the finite difference approximation to the derivatives). ReverseDiff.jl only supports reverse mode, however, so the derivatives calculated by our paraboloid component will be incorrect when run in forward mode (as the warning message tells us). Similarly, if we had chosen ForwardDiff.jl, the reverse-mode derivatives would have been incorrect. So, when looking at the output above, we need to ignore any result that involves Jfor, and just look at the comparisons between Jrev and Jfd. With that in mind, the derivatives look quite good.","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"We can also check the derivatives with the finite difference method:","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"println(prob.check_partials(method=\"cs\"))\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"Same story: the derivatives look good, assuming we just look at the comparisons between Jrev and Jfd. So we're ready to actually run the optimization to verify everything is working properly:","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"prob.run_driver()\nprintln(\"f_xy = $(prob.get_val(\"parab_comp.f_xy\"))\")  # Should print `[-27.33333333]`\nprintln(\"x = $(prob.get_val(\"parab_comp.x\"))\")  # Should print `[6.66666633]`\nprintln(\"y = $(prob.get_val(\"parab_comp.y\"))\")  # Should print `[-7.33333367]`\nnothing # hide","category":"page"},{"location":"matrix_free_ad/","page":"Auto-Matrix-Free Examples","title":"Auto-Matrix-Free Examples","text":"We got the right answer, so everything's good!","category":"page"}]
}
